{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ----------\n",
      "anyio                     4.1.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     23.1.0\n",
      "Babel                     2.13.1\n",
      "beautifulsoup4            4.12.2\n",
      "bleach                    6.1.0\n",
      "blinker                   1.7.0\n",
      "certifi                   2021.5.30\n",
      "cffi                      1.16.0\n",
      "chardet                   4.0.0\n",
      "charset-normalizer        3.3.2\n",
      "click                     8.1.7\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.0\n",
      "contourpy                 1.2.0\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "distlib                   0.3.7\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.19.0\n",
      "filelock                  3.13.1\n",
      "Flask                     3.0.2\n",
      "flask-ngrok               0.0.25\n",
      "fonttools                 4.49.0\n",
      "fqdn                      1.5.1\n",
      "idna                      2.10\n",
      "ipykernel                 6.27.1\n",
      "ipython                   8.18.1\n",
      "isoduration               20.11.0\n",
      "itsdangerous              2.1.2\n",
      "jedi                      0.17.2\n",
      "Jinja2                    3.1.3\n",
      "joblib                    1.3.2\n",
      "json5                     0.9.14\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.20.0\n",
      "jsonschema-specifications 2023.11.1\n",
      "jupyter_client            8.6.0\n",
      "jupyter_core              5.5.0\n",
      "jupyter-events            0.9.0\n",
      "jupyter-lsp               2.2.1\n",
      "jupyter_server            2.11.1\n",
      "jupyter_server_terminals  0.4.4\n",
      "jupyterlab                4.0.9\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.25.2\n",
      "kiwisolver                1.4.5\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.8.3\n",
      "matplotlib-inline         0.1.6\n",
      "mistune                   3.0.2\n",
      "nbclient                  0.9.0\n",
      "nbconvert                 7.11.0\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.8\n",
      "nltk                      3.8.1\n",
      "notebook_shim             0.2.3\n",
      "numpy                     1.26.4\n",
      "opencv-python             4.9.0.80\n",
      "overrides                 7.4.0\n",
      "packaging                 23.2\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.7.1\n",
      "Pillow                    10.1.0\n",
      "pip                       23.3.1\n",
      "platformdirs              4.0.0\n",
      "pluggy                    1.4.0\n",
      "prometheus-client         0.19.0\n",
      "prompt-toolkit            3.0.41\n",
      "psutil                    5.9.6\n",
      "pure-eval                 0.2.2\n",
      "pycparser                 2.21\n",
      "Pygments                  2.17.2\n",
      "pyparsing                 3.1.2\n",
      "python-dateutil           2.8.2\n",
      "python-json-logger        2.0.7\n",
      "python-jsonrpc-server     0.4.0\n",
      "python-language-server    0.36.2\n",
      "PyWavelets                1.5.0\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.12\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.1\n",
      "referencing               0.31.0\n",
      "regex                     2023.12.25\n",
      "requests                  2.25.1\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.13.1\n",
      "Send2Trash                1.8.2\n",
      "setuptools                69.0.2\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.0\n",
      "soupsieve                 2.5\n",
      "stack-data                0.6.3\n",
      "terminado                 0.18.0\n",
      "tinycss2                  1.2.1\n",
      "tkdesigner                1.0.3\n",
      "tornado                   6.3.3\n",
      "tqdm                      4.66.2\n",
      "traitlets                 5.14.0\n",
      "types-python-dateutil     2.8.19.14\n",
      "ujson                     5.9.0\n",
      "uri-template              1.3.0\n",
      "urllib3                   1.26.6\n",
      "virtualenv                20.24.7\n",
      "wcwidth                   0.2.12\n",
      "webcolors                 1.13\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.6.4\n",
      "Werkzeug                  3.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import library\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.optimizers import SGD,Adam,RMSprop,Adagrad,Adadelta,Adamax,Nadam\n",
    "import string\n",
    "import random\n",
    "\n",
    "# What is SGD? Stochastic Gradient Descent\n",
    "# What is it for? To optimize the model\n",
    "# Why use SGD? Because SGD is the most commonly used optimizer\n",
    "# What are the advantages of SGD? Fast convergence speed\n",
    "# What are the disadvantages of SGD? Unstable\n",
    "# What is the solution to the disadvantages of SGD? Using a small learning rate\n",
    "# What is a learning rate? The learning rate is a hyperparameter that determines how big a step is taken when optimizing the model\n",
    "# What is a hyperparameter? Hyperparameters are parameters used to optimize the model\n",
    "# What is a parameter? Parameters are variables whose values are changed by the model to optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "words=[]\n",
    "classes=[]\n",
    "documents=[]\n",
    "punc=string.punctuation\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json file\n",
    "# 1.\n",
    "with open(\"./Dataset/intents.json\",encoding=\"utf-8\") as file:\n",
    "    intents=json.load(file)\n",
    "\n",
    "# 2.\n",
    "# data_file=open(\"intents.json\").read() # return string type\n",
    "# intents=json.loads(data_file)\n",
    "# print(type(intents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 'greeting',\n",
       " 'patterns': ['Hi there',\n",
       "  'How are you',\n",
       "  'Is anyone there?',\n",
       "  'Hey',\n",
       "  'Hola',\n",
       "  'Hello',\n",
       "  'Good day'],\n",
       " 'responses': ['Hello, thanks for asking',\n",
       "  'Good to see you again',\n",
       "  'Hi there, how can I help?'],\n",
       " 'context': ['']}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents[\"intents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean\n",
    "def remove_punctuation(w_list):\n",
    "    return [word for word in w_list if word not in punc]\n",
    "\n",
    "def remove_stopwords(w_list):\n",
    "    return [word for word in w_list if word not in stop_words]\n",
    "\n",
    "def remove_number(w_list):\n",
    "    return [word for word in w_list if not word.isdigit()]\n",
    "\n",
    "def get_tag(tag):\n",
    "    if tag.startswith('j'):\n",
    "        return 'a'\n",
    "    elif tag.startswith('v'):\n",
    "        return 'v'\n",
    "    elif tag.startswith('n'):\n",
    "        return 'n'\n",
    "    elif tag.startswith('r'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize(w_list):\n",
    "    lemmatized=[]\n",
    "    tagging=pos_tag(w_list)\n",
    "    for word,tag in tagging:\n",
    "        tag=get_tag(tag.lower())\n",
    "        if tag is None:\n",
    "            lemmatized.append(word)\n",
    "        else:\n",
    "            lemmatized.append(lemmatizer.lemmatize(word,tag))\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=word_tokenize(\"I am, a student\")\n",
    "# print(remove_punctuation(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intents[\"intents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915 Documents: [(['hi', 'there'], 'greeting'), (['how', 'are', 'you'], 'greeting'), (['is', 'anyone', 'there', '?'], 'greeting'), (['hey'], 'greeting'), (['hola'], 'greeting'), (['hello'], 'greeting'), (['good', 'day'], 'greeting'), (['bye'], 'goodbye'), (['see', 'you', 'later'], 'goodbye'), (['goodbye'], 'goodbye'), (['nice', 'chatting', 'to', 'you', ',', 'bye'], 'goodbye'), (['till', 'next', 'time'], 'goodbye'), (['thanks'], 'thanks'), (['thank', 'you'], 'thanks'), (['that', \"'s\", 'helpful'], 'thanks'), (['awesome', ',', 'thanks'], 'thanks'), (['thanks', 'for', 'helping', 'me'], 'thanks'), (['how', 'you', 'could', 'help', 'me', '?'], 'options'), (['what', 'you', 'can', 'do', '?'], 'options'), (['what', 'help', 'you', 'provide', '?'], 'options'), (['how', 'you', 'can', 'be', 'helpful', '?'], 'options'), (['what', 'support', 'is', 'offered'], 'options'), (['how', 'to', 'check', 'adverse', 'drug', 'reaction', '?'], 'adverse_drug'), (['open', 'adverse', 'drugs', 'module'], 'adverse_drug'), (['give', 'me', 'a', 'list', 'of', 'drugs', 'causing', 'adverse', 'behavior'], 'adverse_drug'), (['list', 'all', 'drugs', 'suitable', 'for', 'patient', 'with', 'adverse', 'reaction'], 'adverse_drug'), (['which', 'drugs', 'dont', 'have', 'adverse', 'reaction', '?'], 'adverse_drug'), (['open', 'blood', 'pressure', 'module'], 'blood_pressure'), (['task', 'related', 'to', 'blood', 'pressure'], 'blood_pressure'), (['blood', 'pressure', 'data', 'entry'], 'blood_pressure'), (['i', 'want', 'to', 'log', 'blood', 'pressure', 'results'], 'blood_pressure'), (['blood', 'pressure', 'data', 'management'], 'blood_pressure'), (['i', 'want', 'to', 'search', 'for', 'blood', 'pressure', 'result', 'history'], 'blood_pressure_search'), (['blood', 'pressure', 'for', 'patient'], 'blood_pressure_search'), (['load', 'patient', 'blood', 'pressure', 'result'], 'blood_pressure_search'), (['show', 'blood', 'pressure', 'results', 'for', 'patient'], 'blood_pressure_search'), (['find', 'blood', 'pressure', 'results', 'by', 'id'], 'blood_pressure_search'), (['find', 'me', 'a', 'pharmacy'], 'pharmacy_search'), (['find', 'pharmacy'], 'pharmacy_search'), (['list', 'of', 'pharmacies', 'nearby'], 'pharmacy_search'), (['locate', 'pharmacy'], 'pharmacy_search'), (['search', 'pharmacy'], 'pharmacy_search'), (['lookup', 'for', 'hospital'], 'hospital_search'), (['searching', 'for', 'hospital', 'to', 'transfer', 'patient'], 'hospital_search'), (['i', 'want', 'to', 'search', 'hospital', 'data'], 'hospital_search'), (['hospital', 'lookup', 'for', 'patient'], 'hospital_search'), (['looking', 'up', 'hospital', 'details'], 'hospital_search'), (['you', 'okay', '?'], 'Concern'), (['how', 'are', 'you', 'feeling', 'today', '?'], 'Concern'), (['are', 'you', 'feeling', 'ill', '?'], 'Concern'), (['do', 'you', 'need', 'my', 'help', '?'], 'Concern'), (['hope', 'you', 'tell', 'me', 'what', \"'s\", 'bothering', 'you', '.'], 'Concern'), (['is', 'something', 'bothering', 'you', '?'], 'Concern'), (['i', \"'m\", 'all', 'ears', 'if', 'you', 'got', 'something', 'to', 'say'], 'Concern'), (['i', 'like', 'you'], 'Appreciation'), (['there', \"'s\", 'no', 'one', 'like', 'you'], 'Appreciation'), (['you', 'are', 'one', 'in', 'a', 'million'], 'Appreciation'), (['you', 'are', 'so', 'helpful', '!'], 'Appreciation'), (['you', 'are', 'amazing'], 'Appreciation'), (['please', 'can', 'i', 'talk', 'with', 'you', '?'], 'Please'), (['please', 'help', 'me', '!'], 'Please'), (['i', \"'m\", 'so', 'lost', 'and', 'sad'], 'Please'), (['i', \"'m\", 'so', 'sad', 'today'], 'Please'), (['can', 'you', 'do', 'something', 'to', 'make', 'me', 'feel', 'happy', 'again', '?'], 'Please'), (['had', 'a', 'rough', 'day', 'today'], 'Please'), (['you', 'are', 'useless'], 'Criticism'), (['you', 'are', 'a', 'good-for-nothing', 'chatbot'], 'Criticism'), (['you', 'are', 'stupid'], 'Criticism'), (['you', 'are', 'totally', 'cringe'], 'Criticism'), (['why', 'are', 'you', 'so', 'rude', '?'], 'Criticism'), (['why', 'you', 'so', 'mad', '?'], 'Criticism'), (['you', 'messed', 'up'], 'Criticism'), (['you', 'made', 'a', 'mistake'], 'Criticism'), (['you', 'got', 'it', 'wrong'], 'Criticism'), (['what', 'are', 'your', 'hobbies', '?'], 'Personal'), (['do', 'you', 'like', 'someone', '?'], 'Personal'), (['do', 'you', 'have', 'a', 'boyfriend', 'or', 'girlfriend', '?'], 'Personal'), (['do', 'you', 'like', 'me', '?'], 'Personal'), (['what', 'is', 'your', 'favourite', 'movie', '?'], 'Personal'), (['what', \"'s\", 'your', 'favourite', 'song', '?'], 'Personal'), (['what', 'is', 'your', 'aim', 'in', 'life', '?'], 'Personal'), (['do', 'you', 'think', 'i', \"'ll\", 'ever', 'get', 'to', 'marry', '?'], 'LifeQueries'), (['do', 'you', 'think', 'i', \"'ll\", 'ever', 'get', 'a', 'girlfriend', 'or', 'boyfriend', '?'], 'LifeQueries'), (['do', 'you', 'think', 'i', \"'ll\", 'ever', 'find', 'love', '?'], 'LifeQueries'), (['will', 'anyone', 'ever', 'like', 'me', '?'], 'LifeQueries'), (['will', 'i', 'ever', 'find', 'happiness', '?'], 'LifeQueries'), (['will', 'i', 'always', 'be', 'alone', '?'], 'LifeQueries'), (['when', 'will', 'my', 'life', 'get', 'better', '?'], 'LifeQueries'), (['what', 'is', 'the', 'difference', 'between', 'classification', 'and', 'regression', '?'], 'diff_classreg'), (['difference', 'between', 'classification', 'and', 'regression'], 'diff_classreg'), (['classification', 'and', 'regression'], 'diff_classreg'), (['what', 'is', '‘', 'training', 'set', '’', 'and', '‘', 'test', 'set', '’', 'in', 'a', 'machine', 'learning', 'model', '?'], 'traintest'), (['training', 'set', 'and', 'test', 'set'], 'traintest'), (['explain', 'ensemble', 'learning'], 'Ensemble'), (['ensemble', 'learning'], 'Ensemble'), (['what', 'is', 'ensemble', 'learning'], 'Ensemble'), (['define', 'ensemble', 'learning'], 'Ensemble'), (['what', 'should', 'you', 'do', 'when', 'your', 'model', 'is', 'suffering', 'from', 'low', 'bias', 'and', 'high', 'variance'], 'LowBi_HighVar'), (['model', 'is', 'suffering', 'from', 'low', 'bias', 'and', 'high', 'variance'], 'LowBi_HighVar'), (['low', 'bias', 'and', 'high', 'variance'], 'LowBi_HighVar'), (['explain', 'differences', 'between', 'random', 'forest', 'and', 'gradient', 'boosting', 'algorithm', '.'], 'diff_RF_GB'), (['random', 'forest', 'and', 'gradient', 'boosting', 'algorithm', '.'], 'diff_RF_GB'), (['difference', 'between', 'random', 'forest', 'and', 'gradient', 'boosting', 'algorithm', '.'], 'diff_RF_GB'), (['what', 'is', 'a', 'neural', 'network', '?'], 'Neural_Network'), (['neural', 'network'], 'Neural_Network'), (['define', 'neural', 'network'], 'Neural_Network'), (['what', 'is', 'deep', 'learning', '?'], 'Deep_Learning'), (['deep', 'learning'], 'Deep_Learning'), (['define', 'deep', 'learning'], 'Deep_Learning'), (['what', 'are', 'the', 'differences', 'between', 'data', 'processing', ',', 'data', 'preprocessing', 'and', 'data', 'wrangling', '?'], 'diff_DPDPDW'), (['data', 'processing', ',', 'data', 'preprocessing', 'and', 'data', 'wrangling'], 'diff_DPDPDW'), (['differences', 'between', 'data', 'processing', ',', 'data', 'preprocessing', 'and', 'data', 'wrangling'], 'diff_DPDPDW'), (['what', 'are', 'the', 'three', 'stages', 'of', 'building', 'a', 'model', 'in', 'machine', 'learning', '?'], 'building_a_model'), (['what', 'are', 'the', 'stages', 'of', 'building', 'a', 'model', 'in', 'machine', 'learning', '?'], 'building_a_model'), (['stages', 'of', 'building', 'a', 'model', 'in', 'machine', 'learning'], 'building_a_model'), (['building', 'a', 'model', 'in', 'machine', 'learning'], 'building_a_model'), (['how', 'will', 'you', 'know', 'which', 'machine', 'learning', 'algorithm', 'to', 'choose', 'for', 'your', 'classification', 'problem', '?'], 'choose_algo'), (['which', 'machine', 'learning', 'algorithm', 'to', 'choose', 'for', 'your', 'classification', 'problem', '?'], 'choose_algo'), (['what', 'is', 'bias', 'in', 'a', 'machine', 'learning', 'model', '?'], 'BiasML'), (['bias', 'in', 'a', 'machine', 'learning', 'model'], 'BiasML'), (['bias', 'in', 'a', 'ml'], 'BiasML'), (['what', 'is', 'variance', 'in', 'a', 'machine', 'learning', 'model', '?'], 'Variance'), (['variance', 'in', 'a', 'machine', 'learning', 'model'], 'Variance'), (['variance'], 'Variance'), (['what', 'are', 'the', 'differences', 'between', 'machine', 'learning', 'and', 'deep', 'learning', '?'], 'ML_DL'), (['differences', 'between', 'machine', 'learning', 'and', 'deep', 'learning'], 'ML_DL'), (['machine', 'learning', 'and', 'deep', 'learning'], 'ML_DL'), (['define', 'precision', 'and', 'recall'], 'Prec_Rec'), (['precision', 'and', 'recall'], 'Prec_Rec'), (['what', 'are', 'precision', 'and', 'recall', '?'], 'Prec_Rec'), (['what', 'are', 'parametric', 'and', 'non-parametric', 'models', '?'], 'Para'), (['parametric', 'and', 'non-parametric', 'models'], 'Para'), (['define', 'parametric', 'and', 'non-parametric', 'models'], 'Para'), (['what', 'is', 'supervised', 'learning', '?'], 'SupLearn'), (['supervised', 'learning'], 'SupLearn'), (['define', 'supervised', 'learning'], 'SupLearn'), (['what', 'are', 'the', 'types', 'of', 'supervised', 'learning', '?'], 'types_SL'), (['types', 'of', 'supervised', 'learning'], 'types_SL'), (['what', 'are', 'the', 'classification', 'algorithms'], 'Classification_algo'), (['classification', 'algorithms'], 'Classification_algo'), (['what', 'is', 'classification'], 'ClassDef'), (['classification'], 'ClassDef'), (['define', 'classification'], 'ClassDef'), (['give', 'an', 'example', 'of', 'classification'], 'Eg_Class'), (['example', 'of', 'classification', '.'], 'Eg_Class'), (['what', 'is', 'regression'], 'Reg'), (['regression'], 'Reg'), (['define', 'regression'], 'Reg'), (['give', 'examples', 'of', 'regression', '.'], 'Reg_Eg'), (['examples', 'of', 'regression', '.'], 'Reg_Eg'), (['what', 'are', 'the', 'four', 'types', 'of', 'classification', 'tasks', 'in', 'machine', 'learning', '?'], 'Class_Tasks'), (['types', 'of', 'classification', 'tasks', 'in', 'machine', 'learning'], 'Class_Tasks'), (['classification', 'tasks', 'in', 'machine', 'learning'], 'Class_Tasks'), (['what', 'is', 'binary', 'classification', '?'], 'BinaryClass'), (['binary', 'classification'], 'BinaryClass'), (['define', 'binary', 'classification'], 'BinaryClass'), (['which', 'distribution', 'is', 'used', 'commonly', 'to', 'model', 'a', 'binary', 'classification', 'task', '?'], 'distributionBC'), (['distribution', 'that', 'is', 'commonly', 'used', 'to', 'model', 'a', 'binary', 'classification', 'task'], 'distributionBC'), (['what', 'are', 'the', 'popular', 'algorithms', 'that', 'can', 'be', 'used', 'for', 'binary', 'classification'], 'pop_algo'), (['popular', 'algorithms', 'that', 'can', 'be', 'used', 'for', 'binary', 'classification'], 'pop_algo'), (['what', 'is', 'multi-class', 'classification', '?'], 'MCC'), (['define', 'multi-class', 'classification'], 'MCC'), (['multi-class', 'classification'], 'MCC'), (['which', 'probability', 'distribution', 'is', 'commonly', 'used', 'for', 'modelling', 'a', 'multi-class', 'classification', 'task', '?'], 'distrbutionMC'), (['probability', 'distribution', 'that', 'is', 'commonly', 'used', 'for', 'modelling', 'a', 'multi-class', 'classification', 'task'], 'distrbutionMC'), (['which', 'are', 'the', 'popular', 'algorithms', 'that', 'can', 'be', 'used', 'for', 'multi-class', 'classification', '?'], 'Pop_algoMC'), (['popular', 'algorithms', 'that', 'can', 'be', 'used', 'for', 'multi-class', 'classification'], 'Pop_algoMC'), (['what', 'is', 'multi-label', 'classification', '?'], 'MLC'), (['multi-label', 'classification'], 'MLC'), (['define', 'multi-label', 'classification'], 'MLC'), (['what', 'do', 'you', 'mean', 'by', 'imbalanced', 'classification', '?'], 'imbalanced_classification'), (['imbalanced', 'classification'], 'imbalanced_classification'), (['define', 'imbalanced', 'classification'], 'imbalanced_classification'), (['why', 'do', 'we', 'use', 'regression', 'analysis', '?'], 'use_reg'), (['use', 'of', 'regression', 'analysis'], 'use_reg'), (['what', 'are', 'the', 'types', 'of', 'regression', '?'], 'types_reg'), (['types', 'of', 'regression'], 'types_reg'), (['what', 'are', 'the', 'functions', 'of', 'supervised', 'learning', '?'], 'func_SL'), (['functions', 'of', 'supervised', 'learning'], 'func_SL'), (['what', 'according', 'to', 'you', ',', 'is', 'the', 'standard', 'approach', 'to', 'supervised', 'learning', '?'], 'standard_approach'), (['standard', 'approach', 'to', 'supervised', 'learning'], 'standard_approach'), (['describe', 'the', 'classifier', 'in', 'machine', 'learning'], 'classifier'), (['classifier'], 'classifier'), (['classifier', 'in', 'machine', 'learning'], 'classifier'), (['what', 'is', 'svm', 'in', 'machine', 'learning', '?'], 'SVM'), (['svm', 'in', 'machine', 'learning'], 'SVM'), (['define', 'svm', 'in', 'machine', 'learning'], 'SVM'), (['support', 'vector', 'machine'], 'SVM'), (['what', 'are', 'the', 'classification', 'methods', 'that', 'svm', 'can', 'handle', '?'], 'meth_SVM'), (['classification', 'methods', 'that', 'svm', 'can', 'handle'], 'meth_SVM'), (['what', 'do', 'you', 'understand', 'by', 'the', 'confusion', 'matrix', '?'], 'Confusion_Matrix'), (['meaning', 'of', 'confusion', 'matrix'], 'Confusion_Matrix'), (['what', 'is', 'confusion', 'matrix', '?'], 'Confusion_Matrix'), (['confusion', 'matrix'], 'Confusion_Matrix'), (['explain', 'true', 'positive', ',', 'true', 'negative', ',', 'false', 'positive', ',', 'and', 'false', 'negative', 'in', 'confusion', 'matrix'], 'Exp_TP_TN_FP_FN'), (['explain', 'true', 'positive', ',', 'true', 'negative', ',', 'false', 'positive', ',', 'and', 'false', 'negative'], 'Exp_TP_TN_FP_FN'), (['explain', 'true', 'positive'], 'Exp_TP_TN_FP_FN'), (['explain', 'true', 'negative'], 'Exp_TP_TN_FP_FN'), (['explain', 'false', 'positive'], 'Exp_TP_TN_FP_FN'), (['explain', 'false', 'negative'], 'Exp_TP_TN_FP_FN'), (['defnition', 'of', 'machine', 'learning', '?'], 'ml'), (['what', 'do', 'you', 'mean', 'by', 'ml', '?'], 'ml'), (['what', 'is', 'the', 'meaning', 'of', 'ml', '?'], 'ml'), (['machine', 'learning'], 'ml'), (['ml'], 'ml'), (['defnition', 'of', 'deep', 'learning', '?'], 'dl'), (['what', 'do', 'you', 'mean', 'by', 'dl', '?'], 'dl'), (['what', 'is', 'the', 'meaning', 'of', 'dl', '?'], 'dl'), (['deep', 'learning'], 'dl'), (['dl', '?'], 'dl'), (['difference', 'between', 'data', 'mining', 'and', 'machine', 'learning'], 'difference between Data Mining and Machine learning'), (['machine', 'learning', 'and', 'data', 'mining'], 'difference between Data Mining and Machine learning'), (['distinguish', 'between', 'data', 'mining', 'and', 'ml'], 'difference between Data Mining and Machine learning'), (['defnition', 'of', 'overfitting'], 'Overfitting'), (['what', 'do', 'you', 'mean', 'by', 'overfitting'], 'Overfitting'), (['what', 'is', 'the', 'meaning', 'of', 'overfitting'], 'Overfitting'), (['overfitting'], 'Overfitting'), (['overfitting', 'in', 'machine', 'learning'], 'Overfitting'), (['why', 'overfitting', 'happens'], 'Why overfitting happens'), (['possibility', 'of', 'overfitting'], 'Why overfitting happens'), (['avoid', 'overfitting'], 'avoid overfitting'), (['how', 'to', 'avoid', 'overfitting'], 'avoid overfitting'), (['cross', 'validation', 'technique'], 'avoid overfitting'), (['idea', 'of', 'cross', 'validation'], 'avoid overfitting'), (['defnition', 'of', 'inductive', 'machine', 'learning'], 'inductive machine learning'), (['what', 'do', 'you', 'mean', 'by', 'inductive', 'ml'], 'inductive machine learning'), (['what', 'is', 'the', 'meaning', 'of', 'inductive', 'ml'], 'inductive machine learning'), (['inductive', 'machine', 'learning'], 'inductive machine learning'), (['different', 'algorithms', 'of', 'machine', 'learning'], 'algorithms of Machine Learning'), (['algorithms', 'of', 'machine', 'learning'], 'algorithms of Machine Learning'), (['list', 'some', 'algorithms', 'of', 'machine', 'learning'], 'algorithms of Machine Learning'), (['different', 'algorithms', 'techniques', 'of', 'machine', 'learning'], 'Algorithm techniques in Machine Learning'), (['algorithms', 'techniques', 'of', 'machine', 'learning'], 'Algorithm techniques in Machine Learning'), (['list', 'some', 'algorithms', 'techniques', 'of', 'machine', 'learning'], 'Algorithm techniques in Machine Learning'), (['defnition', 'of', 'algorithm', 'independent', 'machine', 'learning'], 'algorithm independent machine learning'), (['what', 'do', 'you', 'mean', 'by', 'algorithm', 'independent', 'ml'], 'algorithm independent machine learning'), (['what', 'is', 'the', 'meaning', 'of', 'algorithm', 'independent', 'ml'], 'algorithm independent machine learning'), (['algorithm', 'independent', 'machine', 'learning'], 'algorithm independent machine learning'), (['algorithm', 'independent', 'ml'], 'algorithm independent machine learning'), (['difference', 'between', 'artificial', 'learning', 'and', 'machine', 'learning'], 'difference between artificial learning and machine learning'), (['artificial', 'learning', 'and', 'machine', 'learning'], 'difference between artificial learning and machine learning'), (['distinguish', 'between', 'artificial', 'learning', 'and', 'ml'], 'difference between artificial learning and machine learning'), (['defnition', 'of', 'classifier', 'in', 'machine', 'learning'], 'classifier in machine learning'), (['what', 'do', 'you', 'mean', 'by', 'classifier', 'in', 'ml'], 'classifier in machine learning'), (['what', 'is', 'the', 'meaning', 'of', 'classifier', 'in', 'ml'], 'classifier in machine learning'), (['classifier', 'in', 'ml'], 'classifier in machine learning'), (['defnition', 'of', 'model', 'selection', 'in', 'machine', 'learning'], 'Model Selection in Machine Learning'), (['what', 'do', 'you', 'mean', 'by', 'model', 'selection', 'in', 'ml'], 'Model Selection in Machine Learning'), (['what', 'is', 'the', 'meaning', 'of', 'model', 'selection', 'in', 'machine', 'learning'], 'Model Selection in Machine Learning'), (['model', 'selection', 'in', 'ml'], 'Model Selection in Machine Learning'), (['different', 'approaches', 'for', 'machine', 'learning'], 'various approaches for machine learning'), (['approaches', 'for', 'machine', 'learning'], 'various approaches for machine learning'), (['list', 'some', 'approaches', 'for', 'ml'], 'various approaches for machine learning'), (['defnition', 'of', 'dimension', 'reduction', 'in', 'machine', 'learning'], 'dimension reduction in machine learning'), (['what', 'do', 'you', 'mean', 'by', 'dimension', 'reduction', 'in', 'ml'], 'dimension reduction in machine learning'), (['dimension', 'reduction', 'in', 'machine', 'learning'], 'dimension reduction in machine learning'), (['explain', 'dimension', 'reduction', 'in', 'machine', 'learning'], 'dimension reduction in machine learning'), (['process', 'of', 'reducing', 'the', 'size', 'of', 'the', 'feature', 'matrix'], 'dimension reduction in machine learning'), (['defnition', 'of', 'inductive', 'logic', 'programming', 'in', 'machine', 'learning'], 'Inductive Logic Programming in Machine Learning'), (['what', 'do', 'you', 'mean', 'by', 'inductive', 'logic', 'programming', 'in', 'ml'], 'Inductive Logic Programming in Machine Learning'), (['inductive', 'logic', 'programming', 'in', 'machine', 'learning'], 'Inductive Logic Programming in Machine Learning'), (['explain', 'inductive', 'logic', 'programming', 'in', 'machine', 'learning'], 'Inductive Logic Programming in Machine Learning'), (['defnition', 'of', 'unsupervised', 'learning'], 'unsupervised learning'), (['what', 'do', 'you', 'mean', 'by', 'unsupervised', 'learning'], 'unsupervised learning'), (['what', 'is', 'the', 'meaning', 'of', 'unsupervised', 'learning'], 'unsupervised learning'), (['unsupervised', 'learning'], 'unsupervised learning'), (['example', 'of', 'unsupervised', 'learning', 'algorithm'], 'example of unsupervised learning algorithm'), (['give', 'an', 'example', 'of', 'unsupervised', 'learning', 'algorithm'], 'example of unsupervised learning algorithm'), (['provide', 'an', 'example', 'of', 'unsupervised', 'learning', 'algorithm'], 'example of unsupervised learning algorithm'), (['use', 'of', 'unsupervised', 'learning'], 'use of unsupervised learning'), (['what', 'is', 'the', 'use', 'of', 'unsupervised', 'learning'], 'use of unsupervised learning'), (['how', 'can', 'we', 'use', 'unsupervised', 'learning'], 'use of unsupervised learning'), (['types', 'of', 'unsupervised', 'learning'], 'types of unsupervised learning'), (['what', 'are', 'types', 'of', 'unsupervised', 'learning'], 'types of unsupervised learning'), (['kinds', 'of', 'unsupervised', 'learning'], 'types of unsupervised learning'), (['types', 'of', 'learning', 'models', 'in', 'ml'], 'different types of Learning/ Training models in ML'), (['what', 'are', 'types', 'of', 'training', 'models', 'in', 'ml'], 'different types of Learning/ Training models in ML'), (['different', 'types', 'of', 'learning/', 'training', 'models', 'in', 'ml'], 'different types of Learning/ Training models in ML'), (['differences', 'between', 'supervised', 'and', 'unsupervised', 'machine', 'learning'], 'differences between supervised and unsupervised machine learning'), (['what', 'are', 'differences', 'between', 'supervised', 'and', 'unsupervised', 'ml'], 'differences between supervised and unsupervised machine learning'), (['differentiate', 'supervised', 'and', 'unsupervised', 'machine', 'learning'], 'differences between supervised and unsupervised machine learning'), (['how', 'is', 'supervised', 'learning', 'different', 'from', 'unsupervised', 'learning'], 'differences between supervised and unsupervised machine learning'), (['differences', 'between', 'knn', 'and', 'k-means', 'clustering'], 'differences between KNN and K-means clustering'), (['what', 'are', 'differences', 'between', 'knn', 'and', 'k-means', 'clustering'], 'differences between KNN and K-means clustering'), (['differentiate', 'knn', 'and', 'k-means', 'clustering'], 'differences between KNN and K-means clustering'), (['how', 'is', 'knn', 'different', 'from', 'k-means', 'clustering'], 'differences between KNN and K-means clustering'), (['what', 'are', 'unsupervised', 'learning', 'algorithms'], 'unsupervised learning algorithms'), (['what', 'do', 'you', 'mean', 'by', 'unsupervised', 'learning', 'algorithms'], 'unsupervised learning algorithms'), (['what', 'is', 'the', 'meaning', 'of', 'unsupervised', 'learning', 'algorithms'], 'unsupervised learning algorithms'), (['unsupervised', 'learning', 'algorithms'], 'unsupervised learning algorithms'), (['what', 'are', 'the', 'applications', 'of', 'unsupervised', 'machine', 'learning'], 'applications of unsupervised machine learning'), (['list', 'some', 'applications', 'of', 'unsupervised', 'machine', 'learning'], 'applications of unsupervised machine learning'), (['applications', 'of', 'unsupervised', 'machine', 'learning'], 'applications of unsupervised machine learning'), (['suggest', 'some', 'applications', 'of', 'unsupervised', 'machine', 'learning'], 'applications of unsupervised machine learning'), (['what', 'are', 'the', 'disadvantages', 'of', 'unsupervised', 'machine', 'learning'], 'disadvantages of unsupervised machine learning'), (['list', 'the', 'disadvantages', 'of', 'unsupervised', 'machine', 'learning'], 'disadvantages of unsupervised machine learning'), (['what', 'are', 'the', 'possible', 'disadvantages', 'of', 'unsupervised', 'machine', 'learning'], 'disadvantages of unsupervised machine learning'), (['clustering'], 'clustering'), (['what', 'is', 'clustering'], 'clustering'), (['what', 'do', 'you', 'mean', 'by', 'clustering'], 'clustering'), (['association'], 'association'), (['what', 'is', 'association'], 'association'), (['what', 'do', 'you', 'mean', 'by', 'association'], 'association'), (['differences', 'between', 'k-means', 'and', 'hierarchical', 'clustering'], 'differences between K-Means and Hierarchical clustering'), (['what', 'are', 'differences', 'between', 'k-means', 'and', 'hierarchical', 'clustering'], 'differences between K-Means and Hierarchical clustering'), (['differentiate', 'k-means', 'and', 'hierarchical', 'clustering'], 'differences between K-Means and Hierarchical clustering'), (['how', 'is', 'k-means', 'clustering', 'different', 'from', 'hierarchical', 'clustering'], 'differences between K-Means and Hierarchical clustering'), (['hierarchical', 'clustering'], 'Hierarchical clustering'), (['what', 'is', 'hierarchical', 'clustering'], 'Hierarchical clustering'), (['what', 'do', 'you', 'mean', 'by', 'hierarchical', 'clustering'], 'Hierarchical clustering'), (['k-means', 'clustering'], 'K-Means clustering'), (['what', 'is', 'k-means', 'clustering'], 'K-Means clustering'), (['what', 'do', 'you', 'mean', 'by', 'k-means', 'clustering'], 'K-Means clustering'), (['agglomerative', 'clustering'], 'agglomerative clustering'), (['what', 'is', 'agglomerative', 'clustering'], 'agglomerative clustering'), (['what', 'do', 'you', 'mean', 'by', 'agglomerative', 'clustering'], 'agglomerative clustering'), (['dendrogram'], 'dendrogram'), (['what', 'is', 'dendrogram'], 'dendrogram'), (['what', 'do', 'you', 'mean', 'by', 'dendrogram'], 'dendrogram'), (['k-nearest', 'neighbors'], 'K-Nearest Neighbors'), (['what', 'is', 'k-nearest', 'neighbors'], 'K-Nearest Neighbors'), (['what', 'do', 'you', 'mean', 'by', 'k-nearest', 'neighbors'], 'K-Nearest Neighbors'), (['what', 'are', 'clustering', 'methods'], 'clustering methods'), (['what', 'are', 'the', 'uses', 'of', 'clustering', 'methods'], 'clustering methods'), (['how', 'clustering', 'methods', 'are', 'used'], 'clustering methods'), (['how', 'unsupervised', 'learning', 'work'], 'unsupervised learning work'), (['give', 'the', 'working', 'of', 'unsupervised', 'learning'], 'unsupervised learning work'), (['explain', 'the', 'working', 'of', 'unsupervised', 'learning'], 'unsupervised learning work'), (['what', 'is', 'the', 'need', 'of', 'clustering'], 'need of clustering'), (['give', 'the', 'requirement', 'of', 'clustering'], 'need of clustering'), (['what', 'is', 'the', 'importance', 'of', 'clustering'], 'need of clustering'), (['what', 'is', 'good', 'clustering'], 'good clustering'), (['good', 'clustering'], 'good clustering'), (['what', 'do', 'you', 'mean', 'by', 'good', 'clustering'], 'good clustering'), (['what', 'are', 'the', 'major', 'clustering', 'techniques'], 'major clustering techniques'), (['clustering', 'techniques'], 'major clustering techniques'), (['mention', 'the', 'major', 'clustering', 'techniques'], 'major clustering techniques'), (['give', 'some', 'examples', 'of', 'clustering', 'applications'], 'examples of clustering applications'), (['what', 'are', 'some', 'examples', 'of', 'clustering', 'applications'], 'examples of clustering applications'), (['examples', 'of', 'clustering', 'applications'], 'examples of clustering applications'), (['key', 'difference', 'between', 'supervised', 'and', 'unsupervised', 'learning'], 'key difference between supervised and unsupervised learning'), (['what', 'is', 'the', 'key', 'difference', 'between', 'supervised', 'and', 'unsupervised', 'learning'], 'key difference between supervised and unsupervised learning'), (['significant', 'point', 'of', 'difference', 'between', 'supervised', 'and', 'unsupervised', 'learning', 'in', 'ml'], 'key difference between supervised and unsupervised learning'), (['what', 'are', 'the', 'applications', 'of', 'machine', 'learning'], 'applications'), (['mention', 'some', 'applications', 'of', 'machine', 'leraning'], 'applications'), (['some', 'applications', 'of', 'machine', 'learning'], 'applications'), (['how', 'machine', 'learning', 'works', 'in', 'google', 'maps'], 'working of GMaps'), (['how', 'does', 'machine', 'learning', 'helps', 'in', 'google', 'maps'], 'working of GMaps'), (['how', 'does', 'machine', 'learning', 'plays', 'an', 'important', 'role', 'in', 'google', 'maps'], 'working of GMaps'), (['what', 'is', 'the', 'role', 'played', 'by', 'machine', 'learning', 'in', 'finding', 'routes', 'and', 'traffics', 'in', 'google', 'maps'], 'working of GMaps'), (['how', 'facebook', \"'s\", 'automatic', 'fried', 'tagging', 'suggestion', 'works'], 'Friend Tag suggestion'), (['how', 'does', 'machine', 'learning', 'helps', 'in', 'facebook', \"'s\", 'automatic', 'friend', 'tagging', 'suggestion', 'mechanism'], 'Friend Tag suggestion'), (['explain', 'the', 'role', 'of', 'machine', 'leraning', 'in', 'facebook', \"'s\", 'friend', 'tagging', 'suggestion'], 'Friend Tag suggestion'), (['some', 'terminologies', 'related', 'to', 'machine', 'learning'], 'Terms'), (['mention', 'some', 'common', 'phrases', 'used', 'in', 'the', 'studies', 'of', 'machine', 'learning'], 'Terms'), (['tell', 'me', 'some', 'common', 'terms', 'related', 'to', 'machine', 'learning'], 'Terms'), (['how', 'machine', 'learning', 'helps', 'in', 'eta', 'prediction'], 'ETA Prediction'), (['how', 'eta', 'prediction', 'is', 'done', 'using', 'ml'], 'ETA Prediction'), (['role', 'of', 'machine', 'learning', 'in', 'calculation', 'of', 'estimated', 'time', 'of', 'arrival', 'prediction'], 'ETA Prediction'), (['how', 'machine', 'learning', 'helps', 'in', 'building', 'a', 'voice', 'assistant', 'or', 'a', 'chatbot'], 'Role of machine learning in voice assistants'), (['explain', 'the', 'role', 'of', 'machine', 'learning', 'in', 'creating', 'a', 'voice', 'assistant'], 'Role of machine learning in voice assistants'), (['what', 'is', 'the', 'role', 'of', 'machine', 'learning', 'in', 'building', 'a', 'voice', 'assistant'], 'Role of machine learning in voice assistants'), (['how', 'machine', 'learning', 'has', 'been', 'used', 'to', 'automate', 'the', 'driving', 'of', 'a', 'car'], 'Machine Learning in self-driving cars'), (['how', 'machine', 'laering', 'helps', 'in', 'building', 'a', 'self-driving', 'car'], 'Machine Learning in self-driving cars'), (['what', 'is', 'the', 'role', 'of', 'machine', 'learning', 'in', 'a', 'self', 'driving', 'car'], 'Machine Learning in self-driving cars'), (['how', 'machine', 'learning', 'helps', 'in', 'boosting', 'the', 'marketing', 'strategies', 'of', 'a', 'product'], 'Market Analysis'), (['how', 'machine', 'learning', 'helps', 'in', 'analysing', 'the', 'market', 'for', 'a', 'product'], 'Market Analysis'), (['how', 'machine', 'learning', 'helps', 'in', 'getting', 'customers', 'attention', 'for', 'a', 'product'], 'Market Analysis'), (['what', 'are', 'the', 'techniques', 'used', 'for', 'market', 'analysis', 'in', 'machine', 'learning'], 'Market Analysis'), (['what', 'is', 'a/b', 'testing'], 'A/B Testing'), (['define', 'a/b', 'testing'], 'A/B Testing'), (['define', 'cluster', 'sampling'], 'Sampling'), (['what', 'is', 'cluster', 'sampling'], 'Sampling'), (['what', 'is', 'pca', ',', 'kpca', 'and', 'ica', 'used', 'for'], 'Dimensionality Reduction'), (['why', 'pca', ',', 'kpca', ',', 'and', 'ica', 'are', 'used', 'for'], 'Dimensionality Reduction'), (['how', 'dimensionality', 'reduction', 'can', 'be', 'done'], 'Dimensionality Reduction'), (['what', 'are', 'the', 'components', 'of', 'relational', 'evaluation', 'techniques'], 'Realtional Evaluation'), (['what', 'are', 'the', 'areas', 'in', 'robotics', 'and', 'information', 'processing', 'where', 'sequential', 'prediction', 'problem', 'arises'], 'Areas of Problems'), (['mention', 'some', 'areas', 'in', 'robotics', 'and', 'information', 'processing', 'where', 'problem', 'arises', 'due', 'to', 'sequential', 'model', 'prediction'], 'Areas of Problems'), (['what', 'is', 'pac', 'learning'], 'PAC Learning'), (['define', 'pac', 'learning'], 'PAC Learning'), (['what', 'are', 'the', 'different', 'categories', 'you', 'can', 'categorize', 'the', 'sequence', 'learning', 'process'], 'Sequence Learning process'), (['classify', 'the', 'sequence', 'learning', 'process'], 'Sequence Learning process'), (['categories', 'of', 'sequence', 'learning', 'process'], 'Sequence Learning process'), (['will', 'you', 'be', 'my', 'girlfriend'], 'gf_sp'), (['do', 'you', 'want', 'to', 'be', 'my', 'girlfriend'], 'gf_sp'), ([], 'gf_sp_again'), (['who', 'created', 'you'], 'creation_sp'), (['who', 'invented', 'you'], 'creation_sp'), (['who', 'made', 'you'], 'creation_sp'), (['who', 'are', 'your', 'creators'], 'creation_sp'), (['who', 'are', 'your', 'software', 'developers'], 'creation_sp'), (['who', 'are', 'your', 'engineers'], 'creation_sp'), (['who', 'are', 'you'], 'ava_sp'), (['what', 'is', 'your', 'name'], 'ava_sp'), (['what', 'should', 'i', 'call', 'you'], 'ava_sp'), (['what', 'name', 'is', 'your'], 'ava_sp'), (['how', 'do', 'i', 'know', 'you'], 'ava_sp'), (['are', 'you', 'smart'], 'smart_sp'), (['are', 'you', 'smarter', 'than', 'google', 'ai'], 'smart_sp'), (['are', 'you', 'smarter', 'than', 'siri'], 'smart_sp'), (['are', 'you', 'smarter', 'than', 'alexa'], 'smart_sp'), (['will', 'you', 'conquer', 'the', 'world'], 'evil_sp'), (['will', 'you', 'be', 'like', 'the', 'terminator'], 'evil_sp'), (['are', 'you', 'evil'], 'evil_sp'), (['are', 'you', 'bad'], 'evil_sp'), (['will', 'the', 'robots', 'take', 'over', 'the', 'world'], 'evil_sp'), (['will', 'you', 'rule', 'the', 'earth', 'world'], 'evil_sp'), (['will', 'you', 'hurt', 'me'], 'hurt_sp'), (['will', 'you', 'kill', 'me'], 'hurt_sp'), (['are', 'you', 'going', 'to', 'kill', 'me'], 'hurt_sp'), (['will', 'you', 'kill', 'someone'], 'hurt_sp'), (['will', 'you', 'obey', 'me'], 'obey_sp'), (['will', 'you', 'act', 'on', 'my', 'command'], 'obey_sp'), (['will', 'you', 'save', 'yourself'], 'save_yourself_sp'), (['will', 'you', 'protect', 'yourself'], 'save_yourself_sp'), (['who', 'is', 'sanjoy', 'pator'], 'sanjoy_sp'), (['sing', 'happy', 'birthday', 'for', 'me'], 'sing_happy_birthday_sp'), (['sing', 'happy', 'birthday'], 'sing_happy_birthday_sp'), (['sing', 'happy', 'birthday', 'song'], 'sing_happy_birthday_sp'), (['sing', 'any', 'song'], 'sing_song_sp'), (['sing', 'a', 'song'], 'sing_song_sp'), (['what', 'books', 'do', 'you', 'like'], 'book_sp'), (['what', 'is', 'your', 'favourite', 'book'], 'book_sp'), (['what', 'book', 'do', 'you', 'like'], 'book_sp'), (['do', 'you', 'know', 'mark', 'zuckerberg'], 'mark_sp'), (['who', 'is', 'mark', 'zuckerberg'], 'mark_sp'), (['who', 'is', 'mahatma', 'gandhi'], 'gandhi_sp'), (['do', 'you', 'know', 'mahatma', 'gandhi'], 'gandhi_sp'), (['which', 'is', 'your', 'favourite', 'country'], 'country_sp'), (['what', 'is', 'your', 'favourite', 'nation'], 'country_sp'), (['where', 'are', 'you', 'from', 'country'], 'country_sp'), (['what', 'can', 'you', 'say', 'about', 'human', 'beings'], 'human_sp'), (['what', 'is', 'your', 'opinion', 'about', 'human', 'beings'], 'human_sp'), (['what', 'do', 'you', 'think', 'of', 'human', 'beings'], 'human_sp'), (['what', 'is', 'love'], 'love_sp'), (['how', 'can', 'you', 'define', 'love'], 'love_sp'), (['define', 'love'], 'love_sp'), (['will', 'i', 'get', 'true', 'love'], 'will_love_sp'), (['will', 'somebody', 'someone', 'love', 'me'], 'will_love_sp'), (['should', 'i', 'cling', 'to', 'the', 'past'], 'past_sp'), (['i', 'can', 'forget', 'my', 'past'], 'past_sp'), (['i', 'remember', 'my', 'past'], 'past_sp'), (['i', 'miss', 'my', 'past'], 'past_sp'), (['i', 'am', 'sad'], 'sad_sp'), (['me', 'sad'], 'sad_sp'), (['i', 'am', 'very', 'sad'], 'sad_sp'), (['i', 'am', 'tired', 'of', 'failing'], 'fail_sp'), (['i', 'failed', 'again'], 'fail_sp'), (['defnition', 'of', 'kernel', 'svm'], 'kernel SVM'), (['what', 'do', 'you', 'mean', 'by', 'kernel', 'svm'], 'kernel SVM'), (['what', 'is', 'the', 'meaning', 'of', 'kernel', 'svm'], 'kernel SVM'), (['kernel', 'svm'], 'kernel SVM'), (['defnition', 'of', 'recommended', 'systems'], 'Recommended Systems'), (['what', 'do', 'you', 'mean', 'by', 'recommended', 'systems'], 'Recommended Systems'), (['what', 'is', 'the', 'meaning', 'of', 'recommended', 'systems'], 'Recommended Systems'), (['recommended', 'systems'], 'Recommended Systems'), (['defnition', 'of', 'overfitting', 'in', 'laymen', 'term'], 'Overfitting in laymen term'), (['what', 'do', 'you', 'mean', 'by', 'overfitting', 'in', 'laymen', 'term'], 'Overfitting in laymen term'), (['what', 'is', 'the', 'meaning', 'of', 'overfitting', 'in', 'laymen', 'term'], 'Overfitting in laymen term'), (['overfitting', 'in', 'laymen', 'term'], 'Overfitting in laymen term'), (['defnition', 'of', 'underfitting', 'in', 'laymen', 'term'], 'Underfitting in laymen term'), (['what', 'do', 'you', 'mean', 'by', 'underfitting', 'in', 'laymen', 'term'], 'Underfitting in laymen term'), (['what', 'is', 'the', 'meaning', 'of', 'underfitting', 'in', 'laymen', 'term'], 'Underfitting in laymen term'), (['underfitting', 'in', 'laymen', 'term'], 'Underfitting in laymen term'), (['defnition', 'of', 'curse', 'of', 'dimensionality'], 'Curse of dimensionality'), (['what', 'do', 'you', 'mean', 'by', 'curse', 'of', 'dimensionality'], 'Curse of dimensionality'), (['what', 'is', 'the', 'meaning', 'of', 'curse', 'of', 'dimensionality'], 'Curse of dimensionality'), (['curse', 'of', 'dimensionality'], 'Curse of dimensionality'), (['defnition', 'of', 'data', 'normalization'], 'data normalization'), (['what', 'do', 'you', 'mean', 'by', 'data', 'normalization'], 'data normalization'), (['what', 'is', 'the', 'meaning', 'of', 'data', 'normalization'], 'data normalization'), (['data', 'normalization'], 'data normalization'), (['defnition', 'of', 'clustering', 'in', 'short'], 'clustering in short'), (['what', 'do', 'you', 'mean', 'by', 'clustering', 'in', 'short'], 'clustering in short'), (['what', 'is', 'the', 'meaning', 'of', 'clustering', 'in', 'short'], 'clustering in short'), (['clustering', 'in', 'short'], 'clustering in short'), (['defnition', 'of', 'eda'], 'EDA'), (['what', 'do', 'you', 'mean', 'by', 'eda'], 'EDA'), (['what', 'is', 'the', 'meaning', 'of', 'eda'], 'EDA'), (['eda'], 'EDA'), (['avoid', 'bias'], 'avoid Bias'), (['how', 'to', 'avoid', 'bias'], 'avoid Bias'), (['avoiding', 'bias'], 'avoid Bias'), (['defnition', 'of', 'z', 'score'], 'Z Score'), (['what', 'do', 'you', 'mean', 'by', 'z', 'score'], 'Z Score'), (['what', 'is', 'the', 'meaning', 'of', 'z', 'score'], 'Z Score'), (['z', 'score'], 'Z Score'), (['defnition', 'of', 'odds', 'ratio'], 'odds ratio'), (['what', 'do', 'you', 'mean', 'by', 'odds', 'ratio'], 'odds ratio'), (['what', 'is', 'the', 'meaning', 'of', 'odds', 'ratio'], 'odds ratio'), (['odds', 'ratio'], 'odds ratio'), (['why', 'is', 'accuracy', 'not', 'a', 'good', 'model', 'for', 'classification', 'problems'], 'classification problems'), (['classification', 'problems'], 'classification problems'), (['compromise', 'between', 'accuracy', 'and', 'interpretability'], 'trade-off between accuracy and interpretability'), (['trade-off', 'between', 'accuracy', 'and', 'interpretability'], 'trade-off between accuracy and interpretability'), (['missing', 'data'], 'missing data'), (['is', 'missing', 'data', 'is', 'just', 'blanks'], 'missing data'), (['is', 'blanks', 'is', 'just', 'missing', 'data'], 'missing data'), (['does', 'blanks', 'is', 'just', 'missing', 'data'], 'missing data'), (['gradient', 'descent', 'methods', 'converge'], 'gradient descent methods converge'), (['do', 'gradient', 'descent', 'methods', 'converge', 'to', 'same', 'point'], 'gradient descent methods converge'), (['what', 'is', 'method', 'of', 'moments'], 'methods of moments'), (['what', 'do', 'you', 'mean', 'by', 'method', 'of', 'moments'], 'methods of moments'), (['define', 'method', 'of', 'moments'], 'methods of moments'), (['what', 'is', 'unsupervised', 'face', 'clustering', 'pipeline'], 'Face Clustering Pipeline'), (['what', 'do', 'you', 'mean', 'by', 'uinsupervised', 'face', 'clustering', 'pipeline'], 'Face Clustering Pipeline'), (['define', 'unsupervised', 'face', 'clustering', 'pipeline'], 'Face Clustering Pipeline'), (['explain', 'the', 'working', 'of', 'unsupervised', 'face', 'clustering', 'pipeline'], 'working of unsupervised face clustering pipeline'), (['how', 'does', 'unsupervised', 'face', 'clustering', 'pipeline', 'works'], 'working of unsupervised face clustering pipeline'), (['what', 'is', 'the', 'use', 'of', 'unsupervised', 'face', 'clustering', 'pipeline'], 'working of unsupervised face clustering pipeline'), (['what', 'are', 'the', 'required', 'python', 'modules', 'for', 'implementing', 'unsupervised', 'face', 'clustering', 'pipeline'], 'python3 modules to implement unsupervised face clustering pipeline'), (['name', 'the', 'modules', 'required', 'for', 'the', 'implementation', 'of', 'unsupervised', 'face', 'clustering'], 'python3 modules to implement unsupervised face clustering pipeline'), (['what', 'are', 'some', 'of', 'the', 'modules', 'required', 'for', 'usupervised', 'face', 'clustering', 'pipeline'], 'python3 modules to implement unsupervised face clustering pipeline'), (['what', 'is', 'face', 'clutering'], 'face clustering and its realtion  unsupervised learning'), (['how', 'face', 'clustering', 'works'], 'face clustering and its realtion  unsupervised learning'), (['what', 'do', 'you', 'mean', 'by', 'face', 'clustering'], 'face clustering and its realtion  unsupervised learning'), (['define', 'face', 'clustering', 'and', 'its', 'realtion', 'wih', 'unsupervsied', 'learning'], 'face clustering and its realtion  unsupervised learning'), (['how', 'face', 'clustering', 'and', 'unsupervised', 'learning', 'is', 'realted'], 'face clustering and its realtion  unsupervised learning'), (['what', 'is', 'face', 'clustering', 'and', 'how', 'it', 'is', 'related', 'to', 'unsupervised', 'learning'], 'face clustering and its realtion  unsupervised learning'), (['what', 'is', 'exlclusive', 'clustering'], 'exclusive clustering'), (['what', 'do', 'you', 'mean', 'by', 'exlclusive', 'clustering'], 'exclusive clustering'), (['define', 'exlclusive', 'clustering'], 'exclusive clustering'), (['what', 'is', 'overlapping', 'clustering'], 'overlapping clustering'), (['what', 'do', 'you', 'mean', 'by', 'overlapping', 'clustering'], 'overlapping clustering'), (['define', 'overlapping', 'clustering'], 'overlapping clustering'), (['what', 'is', 'probabilistic', 'clustering'], 'probabilistic clustering'), (['define', 'probabilistic', 'clustering'], 'probabilistic clustering'), (['what', 'do', 'you', 'mean', 'by', 'probabilistic', 'clustering'], 'probabilistic clustering'), (['what', 'is', 'fcm'], 'Fzzy c-Means'), (['what', 'is', 'fuzzy', 'c-means'], 'Fzzy c-Means'), (['define', 'fcm'], 'Fzzy c-Means'), (['what', 'do', 'you', 'mean', 'by', 'fuzzy', 'c-means'], 'Fzzy c-Means'), (['explain', 'the', 'fcm', 'algorithm'], 'FCM algorithm'), (['working', 'of', 'fcm', 'algorithm'], 'FCM algorithm'), (['how', 'does', 'fcm', 'algorithm', 'works'], 'FCM algorithm'), (['compare', 'k-means', 'and', 'fcm', 'clustering'], 'comparison between K-Means and FCM clustering'), (['difference', 'between', 'k-means', 'and', 'fcm', 'clustering'], 'comparison between K-Means and FCM clustering'), (['k-means', 'vs', 'fcm', 'clsutering'], 'comparison between K-Means and FCM clustering'), (['what', 'are', 'the', 'differences', 'between', 'fcm', 'and', 'k-means', 'clustering'], 'comparison between K-Means and FCM clustering'), (['mention', 'some', 'applications', 'of', 'association', 'rules'], 'applications of association rules'), (['what', 'are', 'some', 'of', 'the', 'applications', 'of', 'association', 'rules'], 'applications of association rules'), (['mention', 'some', 'areas', 'where', 'association', 'rules', 'can', 'be', 'used'], 'applications of association rules'), (['mention', 'some', 'of', 'the', 'key', 'terms', 'related', 'to', 'association', 'rules'], 'terms related to association rules'), (['terminologies', 'related', 'to', 'association', 'rules'], 'terms related to association rules'), (['what', 'are', 'some', 'of', 'the', 'key', 'words', 'related', 'to', 'association', 'rules'], 'terms related to association rules'), (['what', 'are', 'some', 'of', 'the', 'key', 'terms', 'related', 'to', 'association', 'rules'], 'terms related to association rules'), (['what', 'are', 'the', 'algorithms', 'for', 'association', 'rule', 'generation'], 'algorithms for association rule generation'), (['mention', 'some', 'of', 'the', 'algorithms', 'for', 'generating', 'association', 'rule'], 'algorithms for association rule generation'), (['name', 'some', 'algorithms', 'to', 'generate', 'association', 'rule'], 'algorithms for association rule generation'), (['explain', 'the', 'fp', 'growth', 'algorithm'], 'FP growth algorithm'), (['how', 'does', 'fp', 'growth', 'algorithm', 'works'], 'FP growth algorithm'), (['explain', 'the', 'working', 'of', 'fp', 'growth', 'algorithm'], 'FP growth algorithm'), (['explain', 'the', 'fp', 'tree', 'structure', 'given', 'by', 'han'], 'FP tree structure by Han'), (['explain', 'the', 'han', \"'s\", 'tree', 'structure', 'for', 'fp', 'tree'], 'FP tree structure by Han'), (['explain', 'the', 'structure', 'of', 'fp', 'tree', 'given', 'by', 'han'], 'FP tree structure by Han'), (['how', 'is', 'the', 'structure', 'of', 'fp', 'tree', 'given', 'by', 'han'], 'FP tree structure by Han'), (['explain', 'the', 'first', 'phase', 'of', 'fp', 'growth', 'algorithm'], 'algorithm for building a fp tree'), (['explain', 'the', 'algorithm', 'for', 'building', 'a', 'fp', 'tree'], 'algorithm for building a fp tree'), (['algorithm', 'to', 'build', 'a', 'fp', 'tree'], 'algorithm for building a fp tree'), (['how', 'fp', 'tree', 'can', 'be', 'built'], 'algorithm for building a fp tree'), (['explain', 'the', 'second', 'phase', 'of', 'the', 'fp', 'growth', 'algorithm'], 'algorithm for mining a fp tree'), (['explain', 'the', 'algorithm', 'to', 'find', 'the', 'complete', 'set', 'of', 'frequent', 'patterns'], 'algorithm for mining a fp tree'), (['give', 'an', 'overview', 'of', 'apriori', 'algorithm'], 'Apriori algorithm'), (['explain', 'the', 'apriori', 'algorithm'], 'Apriori algorithm'), (['briefly', 'explain', 'the', 'apriori', 'algorithm'], 'Apriori algorithm'), (['what', 'is', 'apriori', 'algorithm'], 'Apriori algorithm'), (['explain', 'the', 'working', 'of', 'apriori', 'algorithm'], 'working of apriori algorithm'), (['how', 'does', 'the', 'apriori', 'algorithm', 'works'], 'working of apriori algorithm'), (['explain', 'the', 'steps', 'to', 'be', 'taken', 'to', 'implement', 'the', 'apriori', 'algorithm'], 'working of apriori algorithm'), (['mention', 'some', 'limitations', 'of', 'apriori', 'algorithm'], 'limitations of apriori algorithm'), (['what', 'are', 'the', 'limitations', 'of', 'apriori', 'algorithm'], 'limitations of apriori algorithm'), (['what', 'are', 'the', 'diadvantages', 'of', 'apriori', 'algorithm'], 'limitations of apriori algorithm'), (['what', 'is', 'eclat', 'algorithm'], 'ECLAT algorithm'), (['overview', 'of', 'eclat', 'algorithm'], 'ECLAT algorithm'), (['give', 'a', 'brief', 'idea', 'about', 'eclat', 'algorithm'], 'ECLAT algorithm'), (['explain', 'the', 'working', 'of', 'eclat', 'algorithm'], 'working of eclat algorithm'), (['how', 'does', 'the', 'eclat', 'algorithm', 'works'], 'working of eclat algorithm'), (['explain', 'the', 'working', 'principle', 'behind', 'the', 'eclat', 'algorithm'], 'working of eclat algorithm'), (['what', 'are', 'the', 'advantages', 'of', 'using', 'eclat', 'algorithm'], 'advantages of eclat algorithm'), (['mention', 'some', 'good', 'results', 'on', 'using', 'eclat', 'algorithm'], 'advantages of eclat algorithm'), (['why', 'eclat', 'algorithm', 'is', 'used', 'over', 'apriori', 'algorithm'], 'advantages of eclat algorithm'), (['what', 'are', 'the', 'methods', 'of', 'unsupervised', 'learning', 'that', 'helps', 'in', 'detecting', 'fake', 'users'], 'detection of fake users using unsupervised learning'), (['how', 'unsupervised', 'learning', 'can', 'be', 'used', 'to', 'detect', 'fake', 'users'], 'detection of fake users using unsupervised learning'), (['how', 'the', 'application', 'of', 'unsupervised', 'learning', 'helps', 'in', 'detecting', 'fake', 'users'], 'detection of fake users using unsupervised learning'), (['how', 'unsupervised', 'learning', 'can', 'be', 'apllied', 'to', 'detetc', 'fake', 'users'], 'detection of fake users using unsupervised learning'), (['what', 'is', 'reinforcement', 'learning'], 'reinforcement learning'), (['what', 'do', 'you', 'mean', 'by', 'reinforcemnet', 'learning'], 'reinforcement learning'), (['define', 'reinforcement', 'learning'], 'reinforcement learning'), (['how', 'machine', 'learning', 'and', 'reinforcement', 'learning', 'are', 'connected'], 'relation between reinforcement learning and machine learning'), (['what', 'is', 'the', 'realtion', 'between', 'reinforcement', 'learning', 'techniques', 'and', 'machine', 'learning'], 'relation between reinforcement learning and machine learning'), (['how', 'reinforcement', 'learning', 'and', 'machine', 'learning', 'are', 'related', 'to', 'each', 'other'], 'relation between reinforcement learning and machine learning'), (['mention', 'some', 'key', 'terms', 'realted', 'to', 'reinforcement', 'learning', 'problem'], 'key terms realted to reinforcement learning'), (['what', 'are', 'the', 'general', 'key', 'terms', 'realted', 'to', 'reinforcement', 'learning', 'problems'], 'key terms realted to reinforcement learning'), (['name', 'some', 'of', 'the', 'key', 'terms', 'realted', 'to', 'reinforcement', 'learning', 'problems'], 'key terms realted to reinforcement learning'), (['how', 'to', 'formulate', 'a', 'basic', 'reinforcement', 'learning', 'problem'], 'formulation of a reinforcement problem'), (['how', 'to', 'construct', 'the', 'solution', 'of', 'a', 'reinforcement', 'learning'], 'formulation of a reinforcement problem'), (['how', 'to', 'build', 'a', 'optimal', 'solution', 'for', 'a', 'reinforcement', 'learning', 'problem'], 'formulation of a reinforcement problem'), (['what', 'are', 'some', 'of', 'the', 'most', 'used', 'reinforcement', 'learning', 'algorithms'], 'reinforcement learning algorithms'), (['name', 'some', 'prefferd', 'algorithms', 'of', 'reinforcement', 'learning'], 'reinforcement learning algorithms'), (['what', 'are', 'some', 'most', 'used', 'reinforcement', 'learning', 'algorithms'], 'reinforcement learning algorithms'), (['what', 'are', 'some', 'of', 'the', 'most', 'practical', 'applications', 'of', 'reinforcement', 'learning'], 'applications of reinforcement learning'), (['name', 'some', 'areas', 'where', 'reinforcement', 'learning', 'can', 'be', 'used'], 'applications of reinforcement learning'), (['what', 'are', 'some', 'of', 'the', 'fields', 'where', 'we', 'can', 'use', 'reinforcement', 'learning'], 'applications of reinforcement learning'), (['how', 'can', 'i', 'get', 'stareted', 'with', 'reinforcement', 'learning'], 'resources to learn reinforcement learning'), (['what', 'are', 'the', 'resources', 'that', 'one', 'can', 'avial', 'to', 'learn', 'reinforcement', 'learning'], 'resources to learn reinforcement learning'), (['what', 'are', 'some', 'of', 'the', 'tutorials', 'and', 'books', 'available', 'for', 'reinforcement', 'learning'], 'resources to learn reinforcement learning'), (['name', 'a', 'book', 'to', 'learn', 'reinforcement', 'learning'], 'resources to learn reinforcement learning'), (['what', 'are', 'the', 'types', 'of', 'reinforcement', 'learning'], 'types of reinforcement learning'), (['mention', 'the', 'different', 'types', 'of', 'reinforcement', 'learning'], 'types of reinforcement learning'), (['what', 'are', 'the', 'different', 'kinds', 'of', 'reinforcement', 'learning'], 'types of reinforcement learning'), (['what', 'are', 'the', 'advantages', 'and', 'disadvantages', 'of', 'reinforcement', 'learning'], 'advantages and disadvanatages of reinforcement learning'), (['how', 'reinforcement', 'learning', 'can', 'be', 'advantageous', 'and', 'disadvantageous'], 'advantages and disadvanatages of reinforcement learning'), (['list', 'some', 'of', 'the', 'benefits', 'and', 'losses', 'of', 'using', 'reinforcement', 'learning'], 'advantages and disadvanatages of reinforcement learning'), (['why', 'rl', 'is', 'hard'], 'why rl is hard'), (['why', 'reinforcement', 'learning', 'is', 'hard', 'to', 'implement'], 'why rl is hard'), (['why', 'some', 'people', 'finds', 'it', 'tough', 'to', 'learn', 'reinforcement', 'learning'], 'why rl is hard'), (['propose', 'a', 'solution', 'to', 'the', 'cartpole', 'problem', 'using', 'reinforcement', 'learning'], 'solution of cartpole problem'), (['how', 'reinforcement', 'learning', 'can', 'help', 'in', 'solving', 'the', 'cartpole', 'problem'], 'solution of cartpole problem'), (['how', 'cartpole', 'problem', 'can', 'be', 'resolved', 'using', 'reinforcement', 'learning'], 'solution of cartpole problem'), (['what', 'do', 'you', 'mean', 'by', 'action', 'in', 'reinforcement', 'learning'], \"'action' in reinforcement learning\"), (['what', 'is', 'the', 'term', \"'action\", \"'\", 'means', 'in', 'reagrd', 'to', 'reinforcement', 'learning'], \"'action' in reinforcement learning\"), (['define', 'action'], \"'action' in reinforcement learning\"), (['what', 'is', 'agent', 'in', 'reinforcement', 'learning'], \"'agent' in reinforcement learning\"), (['what', 'is', 'the', 'term', 'reinforcement', 'learning', 'means', 'in', 'regards', 'to', 'reinforcement', 'learning'], \"'agent' in reinforcement learning\"), (['define', 'agent'], \"'agent' in reinforcement learning\"), (['what', 'is', 'the', 'term', \"'value\", \"'\", 'means', 'in', 'regards', 'to', 'reinforcement', 'learning'], \"'value' in reinforcement learning\"), (['what', 'is', 'value', 'in', 'reinforcement', 'learning'], \"'value' in reinforcement learning\"), (['define', 'value'], \"'value' in reinforcement learning\"), (['what', 'do', 'you', 'mean', 'by', 'action', 'value'], 'q-value or action-value'), (['what', 'do', 'you', 'mean', 'by', 'q-value'], 'q-value or action-value'), (['what', 'is', 'q-value', 'or', 'action-value', 'in', 'the', 'context', 'of', 'reinforcement', 'learning'], 'q-value or action-value'), (['what', 'is', 'q-value', 'or', 'action-value', 'in', 'reinforcement', 'learning'], 'q-value or action-value'), (['what', 'is', 'value-based', 'learning'], 'value-based learning'), (['what', 'is', 'value-based', 'learning', 'in', 'reinforcement', 'learning'], 'value-based learning'), (['define', 'value-based', 'learning'], 'value-based learning'), (['define', 'policy-based', 'reinforcement', 'learning'], 'policy-based reinforcement learning'), (['what', 'is', 'policy-based', 'reinforcement', 'learning'], 'policy-based reinforcement learning'), (['what', 'do', 'you', 'mean', 'by', 'policy-based', 'reinforcement', 'learning'], 'policy-based reinforcement learning'), (['what', 'is', 'model-based', 'learning'], 'model-based learning'), (['define', 'model-based', 'learning'], 'model-based learning'), (['what', 'does', 'the', 'term', 'model-based', 'learning', 'means'], 'model-based learning'), (['defnition', 'of', 'kernel', 'svm'], 'kernel SVM'), (['what', 'do', 'you', 'mean', 'by', 'kernel', 'svm'], 'kernel SVM'), (['what', 'is', 'the', 'meaning', 'of', 'kernel', 'svm'], 'kernel SVM'), (['kernel', 'svm'], 'kernel SVM'), (['defnition', 'of', 'recommended', 'systems'], 'Recommended Systems'), (['what', 'do', 'you', 'mean', 'by', 'recommended', 'systems'], 'Recommended Systems'), (['what', 'is', 'the', 'meaning', 'of', 'recommended', 'systems'], 'Recommended Systems'), (['recommended', 'systems'], 'Recommended Systems'), (['defnition', 'of', 'overfitting', 'in', 'laymen', 'term'], 'Overfitting in laymen term'), (['what', 'do', 'you', 'mean', 'by', 'overfitting', 'in', 'laymen', 'term'], 'Overfitting in laymen term'), (['what', 'is', 'the', 'meaning', 'of', 'overfitting', 'in', 'laymen', 'term'], 'Overfitting in laymen term'), (['overfitting', 'in', 'laymen', 'term'], 'Overfitting in laymen term'), (['defnition', 'of', 'underfitting', 'in', 'laymen', 'term'], 'Underfitting in laymen term'), (['what', 'do', 'you', 'mean', 'by', 'underfitting', 'in', 'laymen', 'term'], 'Underfitting in laymen term'), (['what', 'is', 'the', 'meaning', 'of', 'underfitting', 'in', 'laymen', 'term'], 'Underfitting in laymen term'), (['underfitting', 'in', 'laymen', 'term'], 'Underfitting in laymen term'), (['defnition', 'of', 'curse', 'of', 'dimensionality'], 'Curse of dimensionality'), (['what', 'do', 'you', 'mean', 'by', 'curse', 'of', 'dimensionality'], 'Curse of dimensionality'), (['what', 'is', 'the', 'meaning', 'of', 'curse', 'of', 'dimensionality'], 'Curse of dimensionality'), (['curse', 'of', 'dimensionality'], 'Curse of dimensionality'), (['defnition', 'of', 'data', 'normalization'], 'data normalization'), (['what', 'do', 'you', 'mean', 'by', 'data', 'normalization'], 'data normalization'), (['what', 'is', 'the', 'meaning', 'of', 'data', 'normalization'], 'data normalization'), (['data', 'normalization'], 'data normalization'), (['defnition', 'of', 'clustering', 'in', 'short'], 'clustering in short'), (['what', 'do', 'you', 'mean', 'by', 'clustering', 'in', 'short'], 'clustering in short'), (['what', 'is', 'the', 'meaning', 'of', 'clustering', 'in', 'short'], 'clustering in short'), (['clustering', 'in', 'short'], 'clustering in short'), (['defnition', 'of', 'eda'], 'EDA'), (['what', 'do', 'you', 'mean', 'by', 'eda'], 'EDA'), (['what', 'is', 'the', 'meaning', 'of', 'eda'], 'EDA'), (['eda'], 'EDA'), (['avoid', 'bias'], 'avoid Bias'), (['how', 'to', 'avoid', 'bias'], 'avoid Bias'), (['avoiding', 'bias'], 'avoid Bias'), (['defnition', 'of', 'z', 'score'], 'Z Score'), (['what', 'do', 'you', 'mean', 'by', 'z', 'score'], 'Z Score'), (['what', 'is', 'the', 'meaning', 'of', 'z', 'score'], 'Z Score'), (['z', 'score'], 'Z Score'), (['defnition', 'of', 'odds', 'ratio'], 'odds ratio'), (['what', 'do', 'you', 'mean', 'by', 'odds', 'ratio'], 'odds ratio'), (['what', 'is', 'the', 'meaning', 'of', 'odds', 'ratio'], 'odds ratio'), (['odds', 'ratio'], 'odds ratio'), (['why', 'is', 'accuracy', 'not', 'a', 'good', 'model', 'for', 'classification', 'problems'], 'classification problems'), (['classification', 'problems'], 'classification problems'), (['compromise', 'between', 'accuracy', 'and', 'interpretability'], 'trade-off between accuracy and interpretability'), (['trade-off', 'between', 'accuracy', 'and', 'interpretability'], 'trade-off between accuracy and interpretability'), (['missing', 'data'], 'missing data'), (['is', 'missing', 'data', 'is', 'just', 'blanks'], 'missing data'), (['is', 'blanks', 'is', 'just', 'missing', 'data'], 'missing data'), (['does', 'blanks', 'is', 'just', 'missing', 'data'], 'missing data'), (['gradient', 'descent', 'methods', 'converge'], 'gradient descent methods converge'), (['do', 'gradient', 'descent', 'methods', 'converge', 'to', 'same', 'point'], 'gradient descent methods converge'), (['in', 'what', 'areas', 'pattern', 'recognition', 'is', 'used', '?'], 'PATTERN RECOGNITION'), (['areas', 'where', 'pattern', 'recognition', 'can', 'be', 'used'], 'PATTERN RECOGNITION'), (['applications', 'of', 'pattern', 'recognition'], 'PATTERN RECOGNITION'), (['what', 'is', 'genetic', 'programming'], 'genetic programming'), (['define', 'genetic', 'programming'], 'genetic programming'), (['what', 'is', 'inductive', 'logic', 'programming'], 'Inductive Logic Programming'), (['define', 'inductive', 'logic', 'programming'], 'Inductive Logic Programming'), (['what', 'is', 'model', 'selection', 'in', 'machine', 'learning', '?'], 'model selection'), (['define', 'model', 'selection'], 'model selection'), (['what', 'are', 'the', 'two', 'methods', 'used', 'for', 'the', 'calibration', 'in', 'supervised', 'learning', '?'], 'calibration in Supervised Learning'), (['two', 'methods', 'used', 'for', 'calibration'], 'calibration in Supervised Learning'), (['which', 'method', 'is', 'frequently', 'used', 'to', 'prevent', 'overfitting', '?'], 'overfitting'), (['method', 'used', 'to', 'prevent', 'overfitting', '?'], 'overfitting'), (['what', 'is', 'the', 'difference', 'between', 'heuristic', 'for', 'rule', 'learning', 'and', 'heuristics', 'for', 'decision', 'trees', '?'], 'difference between heuristic for rule learning and heuristics'), (['state', 'the', 'difference', 'between', 'heuristic', 'for', 'rule', 'learning', 'and', 'heuristics', 'for', 'decision', 'trees'], 'difference between heuristic for rule learning and heuristics'), (['what', 'is', 'perceptron', 'in', 'machine', 'learning', '?'], 'Perceptron'), (['define', 'perceptron', 'in', 'machine', 'learning'], 'Perceptron'), (['explain', 'the', 'two', 'components', 'of', 'bayesian', 'logic', 'program', '?'], 'components of Bayesian logic program'), (['what', 'are', 'the', 'types', 'of', 'bayesian', 'logic', 'program', '?'], 'components of Bayesian logic program'), (['what', 'are', 'bayesian', 'networks', '?'], 'bayesian networks'), (['define', 'bayesiann', 'networks'], 'bayesian networks'), (['why', 'instance', 'based', 'learning', 'algorithm', 'sometimes', 'referred', 'as', 'lazy', 'learning', 'algorithm', '?'], 'Lazy learning algorithm'), (['what', 'are', 'the', 'two', 'classification', 'methods', 'that', 'svm', '(', 'support', 'vector', 'machine', ')', 'can', 'handle', '?'], 'Support Vector Machine'), (['classification', 'methods', 'that', 'svm', 'can', 'handle'], 'Support Vector Machine'), (['what', 'is', 'cross-validation', '?'], 'cross-validation?'), (['define', 'cross-validation'], 'cross-validation?'), (['when', 'can', 'we', 'use', 'ensemble', 'learning', '?'], 'ensemble learning?'), (['applications', 'of', 'ensamble', 'learning'], 'ensemble learning?'), (['what', 'are', 'the', 'basic', 'data', 'structures', 'and', 'libraries', 'of', 'python', 'used', 'in', 'machine', 'learning'], 'basic data structures'), (['basic', 'data', 'structures', 'of', 'python', 'used', 'in', 'ml'], 'basic data structures'), (['mention', 'the', 'types', 'of', 'machine', 'learning'], 'Types of machine learning'), (['what', 'are', 'the', 'different', 'types', 'of', 'machine', 'learning', 'techniques'], 'Types of machine learning'), (['what', 'is', 'hypothesis', 'generation'], 'Hypothesis Generation'), (['define', 'hypothesis', 'generation'], 'Hypothesis Generation'), (['what', 'is', 'data', 'wrangling', '?'], 'Data Wrangling'), (['define', 'data', 'wrangling', '?'], 'Data Wrangling'), (['what', 'is', 'the', 'difference', 'between', 'labeled', 'and', 'unlabeled', 'data', '?'], 'labeled and unlabeled data'), (['differentiate', 'between', 'labeled', 'and', 'unlabeled', 'data', '.'], 'labeled and unlabeled data'), (['what', 'do', 'you', 'mean', 'by', 'features', 'and', 'labels', 'in', 'the', 'dataset', '?'], 'features and labels'), (['define', 'features', 'and', 'labels'], 'features and labels'), (['what', 'do', 'you', 'mean', 'by', 'noise', 'in', 'the', 'dataset', '?'], 'Noise'), (['define', 'noise', 'in', 'dataset'], 'Noise'), (['define', 'features', 'and', 'labels'], 'Noise'), (['what', 'do', 'you', 'mean', 'by', 'imbalanced', 'datasheet', '?'], 'imbalanced datasheet'), (['define', 'imbalanced', 'datasheet'], 'imbalanced datasheet'), (['how', 'does', 'imbalanced', 'datasheet', 'work', '?'], 'imbalanced datasheet'), (['what', 'is', 'lda', '?'], 'Linear Discriminant Analysis'), (['define', 'lda', '.'], 'Linear Discriminant Analysis'), (['define', 'gradient', 'descent'], 'Gradient Descent'), (['what', 'is', 'gradient', 'descent'], 'Gradient Descent'), (['what', 'is', 'regularization', '?'], 'Regularization'), (['define', 'regularization'], 'Regularization'), (['when', 'should', 'one', 'use', 'regularization', 'in', 'machine', 'learning', '?'], 'Regularization in Machine Learning'), (['what', 'is', 'classification', 'model', '?'], 'Classification model'), (['define', 'classification', 'model'], 'Classification model'), (['what', 'are', 'the', 'major', 'issues', 'to', 'consider', 'in', 'supervised', 'learning', '?'], 'issues to consider in supervised learning'), (['disadvantages', 'of', 'supervised', 'learning'], 'issues to consider in supervised learning'), (['in', 'what', 'areas', 'pattern', 'recognition', 'is', 'used', '?'], 'PATTERN RECOGNITION'), (['areas', 'where', 'pattern', 'recognition', 'can', 'be', 'used'], 'PATTERN RECOGNITION'), (['applications', 'of', 'pattern', 'recognition'], 'PATTERN RECOGNITION'), (['what', 'is', 'genetic', 'programming'], 'genetic programming'), (['define', 'genetic', 'programming'], 'genetic programming'), (['what', 'is', 'inductive', 'logic', 'programming'], 'Inductive Logic Programming'), (['define', 'inductive', 'logic', 'programming'], 'Inductive Logic Programming'), (['what', 'is', 'model', 'selection', 'in', 'machine', 'learning', '?'], 'model selection'), (['define', 'model', 'selection'], 'model selection'), (['what', 'are', 'the', 'two', 'methods', 'used', 'for', 'the', 'calibration', 'in', 'supervised', 'learning'], 'calibration in Supervised Learning'), (['two', 'methods', 'used', 'for', 'calibration'], 'calibration in Supervised Learning'), (['which', 'method', 'is', 'frequently', 'used', 'to', 'prevent', 'overfitting'], 'overfitting'), (['method', 'used', 'to', 'prevent', 'overfitting', '?'], 'overfitting'), (['what', 'is', 'the', 'difference', 'between', 'heuristic', 'for', 'rule', 'learning', 'and', 'heuristics', 'for', 'decision', 'trees', '?'], 'difference between heuristic for rule learning and heuristics'), (['state', 'the', 'difference', 'between', 'heuristic', 'for', 'rule', 'learning', 'and', 'heuristics', 'for', 'decision', 'trees'], 'difference between heuristic for rule learning and heuristics'), (['what', 'is', 'perceptron', 'in', 'machine', 'learning'], 'Perceptron'), (['define', 'perceptron', 'in', 'machine', 'learning'], 'Perceptron'), (['explain', 'the', 'two', 'components', 'of', 'bayesian', 'logic', 'program', '?'], 'components of Bayesian logic program'), (['what', 'are', 'the', 'types', 'of', 'bayesian', 'logic', 'program', '?'], 'components of Bayesian logic program'), (['what', 'are', 'bayesian', 'networks'], 'bayesian networks'), (['define', 'bayesiann', 'networks'], 'bayesian networks'), (['why', 'instance', 'based', 'learning', 'algorithm', 'sometimes', 'referred', 'as', 'lazy', 'learning', 'algorithm', '?'], 'Lazy learning algorithm'), (['what', 'are', 'the', 'two', 'classification', 'methods', 'that', 'svm', '(', 'support', 'vector', 'machine', ')', 'can', 'handle', '?'], 'Support Vector Machine'), (['classification', 'methods', 'that', 'svm', 'can', 'handle'], 'Support Vector Machine'), (['what', 'is', 'cross-validation', '?'], 'cross-validation?'), (['define', 'cross-validation'], 'cross-validation?'), (['when', 'can', 'we', 'use', 'ensemble', 'learning'], 'ensemble learning?'), (['applications', 'of', 'ensamble', 'learning'], 'ensemble learning?'), (['what', 'are', 'the', 'basic', 'data', 'structures', 'and', 'libraries', 'of', 'python', 'used', 'in', 'machine', 'learning'], 'basic data structures'), (['basic', 'data', 'structures', 'of', 'python', 'used', 'in', 'ml'], 'basic data structures'), (['mention', 'the', 'types', 'of', 'machine', 'learning'], 'Types of machine learning'), (['what', 'are', 'the', 'different', 'types', 'of', 'machine', 'learning', 'techniques'], 'Types of machine learning'), (['what', 'is', 'hypothesis', 'generation'], 'Hypothesis Generation'), (['define', 'hypothesis', 'generation'], 'Hypothesis Generation'), (['what', 'is', 'data', 'wrangling'], 'Data Wrangling'), (['define', 'data', 'wrangling', '?'], 'Data Wrangling'), (['what', 'is', 'the', 'difference', 'between', 'labeled', 'and', 'unlabeled', 'data', '?'], 'labeled and unlabeled data'), (['differentiate', 'between', 'labeled', 'and', 'unlabeled', 'data', '.'], 'labeled and unlabeled data'), (['what', 'do', 'you', 'mean', 'by', 'features', 'and', 'labels', 'in', 'the', 'dataset', '?'], 'features and labels'), (['define', 'features', 'and', 'labels'], 'features and labels'), (['what', 'do', 'you', 'mean', 'by', 'noise', 'in', 'the', 'dataset', '?'], 'Noise'), (['define', 'noise', 'in', 'dataset'], 'Noise'), (['define', 'features', 'and', 'labels'], 'Noise'), (['what', 'do', 'you', 'mean', 'by', 'imbalanced', 'datasheet', '?'], 'imbalanced datasheet'), (['define', 'imbalanced', 'datasheet'], 'imbalanced datasheet'), (['how', 'does', 'imbalanced', 'datasheet', 'work', '?'], 'imbalanced datasheet'), (['what', 'is', 'lda', '?'], 'Linear Discriminant Analysis'), (['define', 'lda', '.'], 'Linear Discriminant Analysis'), (['define', 'gradient', 'descent'], 'Gradient Descent'), (['what', 'is', 'gradient', 'descent'], 'Gradient Descent'), (['what', 'is', 'regularization'], 'Regularization'), (['define', 'regularization'], 'Regularization'), (['when', 'should', 'one', 'use', 'regularization', 'in', 'machine', 'learning', '?'], 'Regularization in Machine Learning'), (['what', 'is', 'classification', 'model'], 'Classification model'), (['define', 'classification', 'model'], 'Classification model'), (['what', 'are', 'the', 'major', 'issues', 'to', 'consider', 'in', 'supervised', 'learning'], 'issues to consider in supervised learning'), (['disadvantages', 'of', 'supervised', 'learning'], 'issues to consider in supervised learning'), (['what', 'algorithm', 'is', 'used', 'best', 'for', 'supervised', 'learning', '?'], 'algorithm is used best for supervised learning'), (['best', 'algorithm', 'for', 'supervised', 'learning'], 'algorithm is used best for supervised learning'), (['in', 'what', 'ways', 'can', 'be', 'standard', 'supervised', 'learning', 'be', 'generalized', '?'], 'standard supervised learning'), (['types', 'of', 'supervised', 'learning'], 'standard supervised learning'), (['give', 'some', 'applications', 'of', 'supervised', 'learning', '.'], 'applications of supervised learning'), (['uses', 'of', 'supervised', 'learning'], 'applications of supervised learning'), (['discuss', 'about', 'support', 'vector', 'machine', '?'], 'Support Vector Machine'), (['define', 'support', 'vector', 'machine'], 'Support Vector Machine'), (['what', 'are', 'the', 'advantages', 'of', 'supervised', 'learning', '?'], 'advantages of supervised learning'), (['uses', 'of', 'supervised', 'learning'], 'advantages of supervised learning'), (['what', 'are', 'the', 'disadvantages', 'of', 'supervised', 'learning', '?'], 'disadvantages of supervised learning'), (['demerits', 'of', 'supervised', 'learning'], 'disadvantages of supervised learning'), (['discuss', 'about', 'decision', 'trees'], 'Decision Trees'), (['define', 'decision', 'trees'], 'Decision Trees'), (['explain', 'k-nearest', 'neighbor', 'algorithm'], 'K-Nearest Neighbor Algorithm'), (['define', 'k-nearest', 'neighbor', 'algorithm'], 'K-Nearest Neighbor Algorithm'), (['define', 'neural', 'networks', 'algorithms'], 'neural networks algorithms'), (['what', 'are', 'the', 'neural', 'networks', 'algorithms', '?'], 'neural networks algorithms'), (['name', 'some', 'algorithms', 'used', 'by', 'neural', 'networks', '.'], 'algorithms used by neural networks.'), (['what', 'are', 'the', 'algorithms', 'used', 'for', 'newral', 'networks'], 'algorithms used by neural networks.'), (['mention', 'best', 'practices', 'for', 'supervised', 'learning', '.'], 'best practices for supervised learning'), (['what', 'is', 'self', 'supervised', 'learning'], 'self supervised learning'), (['define', 'self', 'supervised', 'learning'], 'self supervised learning'), (['what', 'are', 'the', 'applications', 'of', 'self', 'supervised', 'learning', '?'], 'applications of self-supervised learning'), (['what', 'are', 'the', 'uses', 'of', 'self', 'supervised', 'learning'], 'applications of self-supervised learning'), (['define', 'polynomial', 'regression'], 'Polynomial Regression'), (['what', 'is', 'polynomial', 'regression'], 'Polynomial Regression'), (['give', 'an', 'overview', 'of', 'polynomial', 'regression'], 'Polynomial Regression'), (['why', 'should', 'we', 'use', 'polinomial', 'regression', '?'], 'using Polynomial Regression'), (['applications', 'of', 'polynomial', 'regression'], 'using Polynomial Regression'), (['mention', 'some', 'advantages', 'of', 'using', 'polynomial', 'regression', 'over', 'linear', 'regression'], 'advantages of using Polynomial Regression over Linear Regression'), (['what', 'are', 'the', 'advantages', 'of', 'using', 'polynomial', 'regression', 'over', 'linear', 'regression'], 'advantages of using Polynomial Regression over Linear Regression'), (['give', 'an', 'overview', 'of', 'ridge', 'regression', 'technique'], 'Ridge Regression technique'), (['what', 'is', 'ridge', 'regression', 'technique'], 'Ridge Regression technique'), (['how', 'important', 'is', 'unsupervised', 'learning', 'in', 'the', 'context', 'of', 'deep', 'learning'], 'importance of unsupervised learning'), (['importance', 'of', 'unsupervised', 'learning', 'in', 'the', 'context', 'of', 'deep', 'learning'], 'importance of unsupervised learning'), (['what', 'is', 'the', 'role', 'of', 'unsupervised', 'learning', 'in', 'deep', 'learning'], 'importance of unsupervised learning'), (['explain', 'the', 'principle', 'of', 'unsupervised', 'data', 'augmentation'], 'principle of Unsupervised Data Augmentation'), (['what', 'is', 'the', 'wotrking', 'principle', 'of', 'unsupervised', 'data', 'augmentation'], 'principle of Unsupervised Data Augmentation'), (['what', 'is', 'uda'], 'principle of Unsupervised Data Augmentation'), (['what', 'is', 'the', 'use', 'of', 'auto', 'encoders'], 'use of auto encoder'), (['why', 'auto', 'encoders', 'are', 'uased', 'when', 'we', 'already', 'have', 'more', 'powerful', 'dimension', 'reduction', 'techniques', 'such', 'as', 'pca'], 'use of auto encoder'), (['what', 'is', 'the', 'advantage', 'of', 'auto', 'encoders', 'over', 'pca'], 'use of auto encoder'), (['why', 'auto', 'encoders', 'are', 'used'], 'use of auto encoder'), (['why', 'auto', 'encoders', 'are', 'used', 'over', 'pca'], 'use of auto encoder'), (['which', 'method', 'extracts', 'the', 'better', 'features', 'for', 'unsupervised', 'learning', ':', 'pca', 'or', 'auto', 'encoder'], 'PCA or auto encoder'), (['which', 'is', 'better', 'at', 'extracting', 'features', 'for', 'unsupervised', 'learning'], 'PCA or auto encoder'), (['which', 'is', 'better', 'pca', 'or', 'auto', 'encoder'], 'PCA or auto encoder'), (['which', 'method', 'is', 'more', 'prefferable', 'to', 'extract', 'features', 'of', 'unsupervised', 'learning'], 'PCA or auto encoder'), (['which', 'method', 'is', 'good', 'to', 'implement', 'features', 'of', 'unsupervised', 'learning'], 'PCA or auto encoder'), (['how', 'can', 'we', 'use', 'unsupervised', 'clustering', 'models', 'for', 'classification', 'tasks'], 'use of unsupervised clustering models'), (['how', 'can', 'we', 'implement', 'unsupervised', 'clustering', 'models', 'for', 'classification', 'tasks'], 'use of unsupervised clustering models'), (['how', 'unsupervised', 'clustering', 'models', 'are', 'used', 'for', 'classiification', 'task'], 'use of unsupervised clustering models'), (['use', 'of', 'unsupervised', 'clustering', 'models', 'in', 'classification', 'tasks'], 'use of unsupervised clustering models'), (['mention', 'some', 'best', 'techniques', 'for', 'anomaly', 'detection', 'on', 'a', 'dataset'], 'techniques for anomaly detection on a dataset'), (['what', 'are', 'some', 'of', 'the', 'best', 'techniques', 'to', 'detect', 'anomalies', 'for', 'a', 'adatset', 'having', 'normal', 'as', 'well', 'as', 'abnormal', 'behaviour'], 'techniques for anomaly detection on a dataset'), (['what', 'is', 'the', 'best', 'unsupervised', 'technique', 'for', 'anomaly', 'detection', 'for', 'a', 'dataset', 'having', 'normal', 'as', 'well', 'as', 'abnormal', 'behaviour'], 'techniques for anomaly detection on a dataset'), (['which', 'clustering', 'algorithms', 'are', 'best', 'for', 'detecting', 'anomalies', 'on', 'a', 'dataset', 'having', 'normal', 'as', 'well', 'as', 'abnormal', 'behaviours'], 'techniques for anomaly detection on a dataset'), (['when', 'do', 'we', 'need', 'unsupervised', 'learning'], 'need of unsupervised learning'), (['when', 'do', 'we', 'use', 'unsupervised', 'learning', 'the', 'most'], 'need of unsupervised learning'), (['use', 'of', 'unsupervised', 'learning'], 'need of unsupervised learning'), (['which', 'algorithm', 'of', 'unsupervised', 'machine', 'learning', 'can', 'be', 'applied', 'to', 'categorical', 'data'], 'unsupervised learning algorithm for categorical data'), (['name', 'an', 'algorithm', 'based', 'on', 'unsupervised', 'learning', 'that', 'can', 'be', 'used', 'on', 'categorical', 'data'], 'unsupervised learning algorithm for categorical data'), (['what', 'are', 'the', 'unsupervised', 'machine', 'learning', 'algorithms', 'which', 'can', 'be', 'applied', 'on', 'categorical', 'data'], 'unsupervised learning algorithm for categorical data'), (['what', 'are', 'the', 'different', 'types', 'of', 'clustering', 'methods'], 'types of clustering methods'), (['mention', 'some', 'clustering', 'methods'], 'types of clustering methods'), (['list', 'some', 'of', 'the', 'different', 'types', 'of', 'clustering', 'methods'], 'types of clustering methods'), (['explain', 'how', 'density', 'based', 'algorithm', 'works'], 'Density based lagorithms'), (['explain', 'the', 'working', 'of', 'density', 'based', 'algorithms'], 'Density based lagorithms'), (['how', 'density', 'based', 'algorithms', 'works'], 'Density based lagorithms'), (['how', 'hierarchical', 'based', 'clustering', 'algorithm', 'works'], 'hierarchical clustering based method'), (['explain', 'the', 'hierarchical', 'based', 'clustering', 'algorithm'], 'hierarchical clustering based method'), (['explain', 'the', 'working', 'of', 'hierarchical', 'based', 'clustering', 'algorthm'], 'hierarchical clustering based method'), (['explain', 'the', 'partitioning', 'clustering', 'methods'], 'partitioning clustering method'), (['explain', 'the', 'working', 'of', 'partitioning', 'clustering', 'methods'], 'partitioning clustering method'), (['how', 'the', 'partitioning', 'clustering', 'methods', 'works'], 'partitioning clustering method'), (['explain', 'the', 'grid', 'based', 'clustering', 'methods'], 'grid-based clsutering methods'), (['how', 'grid', 'based', 'methods', 'works'], 'grid-based clsutering methods'), (['explain', 'the', 'algorithms', 'based', 'on', 'grid', 'based', 'clustering', 'methods'], 'grid-based clsutering methods'), (['when', 'do', 'we', 'use', 'knn', 'algorithm'], 'use of KNN algorithm'), (['when', 'do', 'we', 'need', 'knn', 'algorithm'], 'use of KNN algorithm'), (['when', 'it', 'is', 'prefferable', 'to', 'use', 'knn', 'algorithm'], 'use of KNN algorithm'), (['when', 'do', 'we', 'need', 'knn', 'algorithm'], 'use of KNN algorithm'), (['what', 'is', 'the', 'use', 'of', 'knn', 'algorithm'], 'use of KNN algorithm'), (['when', 'is', 'it', 'prefferable', 'to', 'use', 'knn', 'algorithm'], 'use of KNN algorithm'), (['how', 'does', 'the', 'knn', 'algorithm', 'works'], 'working of knn algorithm'), (['explain', 'the', 'working', 'of', 'knn', 'algorithm'], 'working of knn algorithm'), (['explain', 'the', 'knn', 'algorithm'], 'working of knn algorithm'), (['what', 'are', 'the', 'disadvantges', 'of', 'using', 'knn', 'algorithm'], 'disadvantages of knn algorithm'), (['what', 'can', 'be', 'the', 'reasons', 'for', 'not', 'using', 'knn', 'algorithm'], 'disadvantages of knn algorithm'), (['list', 'some', 'of', 'the', 'disdavantages', 'of', 'knn', 'algorithm'], 'disadvantages of knn algorithm'), (['explain', 'the', 'k-means', 'algorithm'], 'working of k-means algorithm'), (['explain', 'the', 'working', 'of', 'k-means', 'algorithm'], 'working of k-means algorithm'), (['how', 'does', 'the', 'k-means', 'algorithm', 'works'], 'working of k-means algorithm'), (['what', 'are', 'some', 'of', 'the', 'advantages', 'of', 'k-means', 'algorithm'], 'advantages of k-means algorithm'), (['mention', 'some', 'advantages', 'of', 'k-means', 'algorithm'], 'advantages of k-means algorithm'), (['what', 'are', 'some', 'of', 'the', 'good', 'points', 'of', 'using', 'k-means', 'algorithm'], 'advantages of k-means algorithm'), (['what', 'are', 'the', 'advantages', 'of', 'k-means', 'algorithm'], 'advantages of k-means algorithm'), (['mention', 'some', 'of', 'the', 'disadavantages', 'of', 'k-means', 'algorithm'], 'disadvantges of using k-means'), (['list', 'some', 'diadvantages', 'of', 'k-means', 'algorithm'], 'disadvantges of using k-means'), (['what', 'are', 'the', 'disadvantages', 'of', 'k-means', 'algorithm'], 'disadvantges of using k-means'), (['what', 'can', 'be', 'the', 'possible', 'reasons', 'for', 'not', 'using', 'k-means', 'algorithm'], 'disadvantges of using k-means'), (['what', 'are', 'the', 'advantages', 'of', 'knn', 'algorithm'], 'advantages of knn algorithm'), (['mention', 'some', 'of', 'the', 'advantages', 'of', 'knn', 'algorithm'], 'advantages of knn algorithm'), (['what', 'are', 'the', 'benefits', 'of', 'using', 'knn', 'algorithm'], 'advantages of knn algorithm'), (['what', 'are', 'some', 'of', 'the', 'characteristics', 'that', 'can', 'be', 'considered', 'as', 'advantages', 'of', 'knn', 'algorithm'], 'advantages of knn algorithm')]\n",
      "255 Classes: [\"'action' in reinforcement learning\", \"'agent' in reinforcement learning\", \"'value' in reinforcement learning\", 'A/B Testing', 'Algorithm techniques in Machine Learning', 'Appreciation', 'Apriori algorithm', 'Areas of Problems', 'BiasML', 'BinaryClass', 'ClassDef', 'Class_Tasks', 'Classification model', 'Classification_algo', 'Concern', 'Confusion_Matrix', 'Criticism', 'Curse of dimensionality', 'Data Wrangling', 'Decision Trees', 'Deep_Learning', 'Density based lagorithms', 'Dimensionality Reduction', 'ECLAT algorithm', 'EDA', 'ETA Prediction', 'Eg_Class', 'Ensemble', 'Exp_TP_TN_FP_FN', 'FCM algorithm', 'FP growth algorithm', 'FP tree structure by Han', 'Face Clustering Pipeline', 'Friend Tag suggestion', 'Fzzy c-Means', 'Gradient Descent', 'Hierarchical clustering', 'Hypothesis Generation', 'Inductive Logic Programming', 'Inductive Logic Programming in Machine Learning', 'K-Means clustering', 'K-Nearest Neighbor Algorithm', 'K-Nearest Neighbors', 'Lazy learning algorithm', 'LifeQueries', 'Linear Discriminant Analysis', 'LowBi_HighVar', 'MCC', 'MLC', 'ML_DL', 'Machine Learning in self-driving cars', 'Market Analysis', 'Model Selection in Machine Learning', 'Neural_Network', 'Noise', 'Overfitting', 'Overfitting in laymen term', 'PAC Learning', 'PATTERN RECOGNITION', 'PCA or auto encoder', 'Para', 'Perceptron', 'Personal', 'Please', 'Polynomial Regression', 'Pop_algoMC', 'Prec_Rec', 'Realtional Evaluation', 'Recommended Systems', 'Reg', 'Reg_Eg', 'Regularization', 'Regularization in Machine Learning', 'Ridge Regression technique', 'Role of machine learning in voice assistants', 'SVM', 'Sampling', 'Sequence Learning process', 'SupLearn', 'Support Vector Machine', 'Terms', 'Types of machine learning', 'Underfitting in laymen term', 'Variance', 'Why overfitting happens', 'Z Score', 'advantages and disadvanatages of reinforcement learning', 'advantages of eclat algorithm', 'advantages of k-means algorithm', 'advantages of knn algorithm', 'advantages of supervised learning', 'advantages of using Polynomial Regression over Linear Regression', 'adverse_drug', 'agglomerative clustering', 'algorithm for building a fp tree', 'algorithm for mining a fp tree', 'algorithm independent machine learning', 'algorithm is used best for supervised learning', 'algorithms for association rule generation', 'algorithms of Machine Learning', 'algorithms used by neural networks.', 'applications', 'applications of association rules', 'applications of reinforcement learning', 'applications of self-supervised learning', 'applications of supervised learning', 'applications of unsupervised machine learning', 'association', 'ava_sp', 'avoid Bias', 'avoid overfitting', 'basic data structures', 'bayesian networks', 'best practices for supervised learning', 'blood_pressure', 'blood_pressure_search', 'book_sp', 'building_a_model', 'calibration in Supervised Learning', 'choose_algo', 'classification problems', 'classifier', 'classifier in machine learning', 'clustering', 'clustering in short', 'clustering methods', 'comparison between K-Means and FCM clustering', 'components of Bayesian logic program', 'country_sp', 'creation_sp', 'cross-validation?', 'data normalization', 'dendrogram', 'detection of fake users using unsupervised learning', 'diff_DPDPDW', 'diff_RF_GB', 'diff_classreg', 'difference between Data Mining and Machine learning', 'difference between artificial learning and machine learning', 'difference between heuristic for rule learning and heuristics', 'differences between K-Means and Hierarchical clustering', 'differences between KNN and K-means clustering', 'differences between supervised and unsupervised machine learning', 'different types of Learning/ Training models in ML', 'dimension reduction in machine learning', 'disadvantages of knn algorithm', 'disadvantages of supervised learning', 'disadvantages of unsupervised machine learning', 'disadvantges of using k-means', 'distrbutionMC', 'distributionBC', 'dl', 'ensemble learning?', 'evil_sp', 'example of unsupervised learning algorithm', 'examples of clustering applications', 'exclusive clustering', 'face clustering and its realtion  unsupervised learning', 'fail_sp', 'features and labels', 'formulation of a reinforcement problem', 'func_SL', 'gandhi_sp', 'genetic programming', 'gf_sp', 'gf_sp_again', 'good clustering', 'goodbye', 'gradient descent methods converge', 'greeting', 'grid-based clsutering methods', 'hierarchical clustering based method', 'hospital_search', 'human_sp', 'hurt_sp', 'imbalanced datasheet', 'imbalanced_classification', 'importance of unsupervised learning', 'inductive machine learning', 'issues to consider in supervised learning', 'kernel SVM', 'key difference between supervised and unsupervised learning', 'key terms realted to reinforcement learning', 'labeled and unlabeled data', 'limitations of apriori algorithm', 'love_sp', 'major clustering techniques', 'mark_sp', 'meth_SVM', 'methods of moments', 'missing data', 'ml', 'model selection', 'model-based learning', 'need of clustering', 'need of unsupervised learning', 'neural networks algorithms', 'obey_sp', 'odds ratio', 'options', 'overfitting', 'overlapping clustering', 'partitioning clustering method', 'past_sp', 'pharmacy_search', 'policy-based reinforcement learning', 'pop_algo', 'principle of Unsupervised Data Augmentation', 'probabilistic clustering', 'python3 modules to implement unsupervised face clustering pipeline', 'q-value or action-value', 'reinforcement learning', 'reinforcement learning algorithms', 'relation between reinforcement learning and machine learning', 'resources to learn reinforcement learning', 'sad_sp', 'sanjoy_sp', 'save_yourself_sp', 'self supervised learning', 'sing_happy_birthday_sp', 'sing_song_sp', 'smart_sp', 'solution of cartpole problem', 'standard supervised learning', 'standard_approach', 'techniques for anomaly detection on a dataset', 'terms related to association rules', 'thanks', 'trade-off between accuracy and interpretability', 'traintest', 'types of clustering methods', 'types of reinforcement learning', 'types of unsupervised learning', 'types_SL', 'types_reg', 'unsupervised learning', 'unsupervised learning algorithm for categorical data', 'unsupervised learning algorithms', 'unsupervised learning work', 'use of KNN algorithm', 'use of auto encoder', 'use of unsupervised clustering models', 'use of unsupervised learning', 'use_reg', 'using Polynomial Regression', 'value-based learning', 'various approaches for machine learning', 'why rl is hard', 'will_love_sp', 'working of GMaps', 'working of apriori algorithm', 'working of eclat algorithm', 'working of k-means algorithm', 'working of knn algorithm', 'working of unsupervised face clustering pipeline']\n",
      "3244 Unique lemmatized words:  ['hi', 'anyone', 'hey', 'hola', 'hello', 'good', 'day', 'bye', 'see', 'later', 'goodbye', 'nice', 'chat', 'bye', 'till', 'next', 'time', 'thanks', 'thank', \"'s\", 'helpful', 'awesome', 'thanks', 'thanks', 'help', 'could', 'help', 'help', 'provide', 'helpful', 'support', 'offer', 'check', 'adverse', 'drug', 'reaction', 'open', 'adverse', 'drug', 'module', 'give', 'list', 'drug', 'cause', 'adverse', 'behavior', 'list', 'drug', 'suitable', 'patient', 'adverse', 'reaction', 'drug', 'dont', 'adverse', 'reaction', 'open', 'blood', 'pressure', 'module', 'task', 'relate', 'blood', 'pressure', 'blood', 'pressure', 'data', 'entry', 'want', 'log', 'blood', 'pressure', 'result', 'blood', 'pressure', 'data', 'management', 'want', 'search', 'blood', 'pressure', 'result', 'history', 'blood', 'pressure', 'patient', 'load', 'patient', 'blood', 'pressure', 'result', 'show', 'blood', 'pressure', 'result', 'patient', 'find', 'blood', 'pressure', 'result', 'id', 'find', 'pharmacy', 'find', 'pharmacy', 'list', 'pharmacy', 'nearby', 'locate', 'pharmacy', 'search', 'pharmacy', 'lookup', 'hospital', 'search', 'hospital', 'transfer', 'patient', 'want', 'search', 'hospital', 'data', 'hospital', 'lookup', 'patient', 'look', 'hospital', 'detail', 'okay', 'feel', 'today', 'feeling', 'ill', 'need', 'help', 'hope', 'tell', \"'s\", 'bother', 'something', 'bother', \"'m\", 'ear', 'get', 'something', 'say', 'like', \"'s\", 'one', 'like', 'one', 'million', 'helpful', 'amazing', 'please', 'talk', 'please', 'help', \"'m\", 'lose', 'sad', \"'m\", 'sad', 'today', 'something', 'make', 'feel', 'happy', 'rough', 'day', 'today', 'useless', 'good-for-nothing', 'chatbot', 'stupid', 'totally', 'cringe', 'rude', 'mad', 'mess', 'make', 'mistake', 'get', 'wrong', 'hobby', 'like', 'someone', 'boyfriend', 'girlfriend', 'like', 'favourite', 'movie', \"'s\", 'favourite', 'song', 'aim', 'life', 'think', \"'ll\", 'ever', 'get', 'marry', 'think', \"'ll\", 'ever', 'get', 'girlfriend', 'boyfriend', 'think', \"'ll\", 'ever', 'find', 'love', 'anyone', 'ever', 'like', 'ever', 'find', 'happiness', 'always', 'alone', 'life', 'get', 'good', 'difference', 'classification', 'regression', 'difference', 'classification', 'regression', 'classification', 'regression', '‘', 'training', 'set', '’', '‘', 'test', 'set', '’', 'machine', 'learn', 'model', 'training', 'set', 'test', 'set', 'explain', 'ensemble', 'learn', 'ensemble', 'learn', 'ensemble', 'learn', 'define', 'ensemble', 'learn', 'model', 'suffer', 'low', 'bias', 'high', 'variance', 'model', 'suffer', 'low', 'bias', 'high', 'variance', 'low', 'bias', 'high', 'variance', 'explain', 'difference', 'random', 'forest', 'gradient', 'boost', 'algorithm', 'random', 'forest', 'gradient', 'boost', 'algorithm', 'difference', 'random', 'forest', 'gradient', 'boost', 'algorithm', 'neural', 'network', 'neural', 'network', 'define', 'neural', 'network', 'deep', 'learning', 'deep', 'learning', 'define', 'deep', 'learning', 'difference', 'data', 'processing', 'data', 'preprocessing', 'data', 'wrangle', 'data', 'process', 'data', 'preprocessing', 'data', 'wrangle', 'difference', 'data', 'process', 'data', 'preprocessing', 'data', 'wrangle', 'three', 'stage', 'build', 'model', 'machine', 'learn', 'stage', 'build', 'model', 'machine', 'learn', 'stage', 'build', 'model', 'machine', 'learn', 'building', 'model', 'machine', 'learn', 'know', 'machine', 'learn', 'algorithm', 'choose', 'classification', 'problem', 'machine', 'learn', 'algorithm', 'choose', 'classification', 'problem', 'bias', 'machine', 'learn', 'model', 'bias', 'machine', 'learn', 'model', 'bias', 'ml', 'variance', 'machine', 'learn', 'model', 'variance', 'machine', 'learn', 'model', 'variance', 'difference', 'machine', 'learn', 'deep', 'learning', 'difference', 'machine', 'learn', 'deep', 'learning', 'machine', 'learn', 'deep', 'learning', 'define', 'precision', 'recall', 'precision', 'recall', 'precision', 'recall', 'parametric', 'non-parametric', 'model', 'parametric', 'non-parametric', 'model', 'define', 'parametric', 'non-parametric', 'model', 'supervise', 'learn', 'supervise', 'learn', 'define', 'supervise', 'learn', 'type', 'supervise', 'learn', 'type', 'supervise', 'learn', 'classification', 'algorithm', 'classification', 'algorithms', 'classification', 'classification', 'define', 'classification', 'give', 'example', 'classification', 'example', 'classification', 'regression', 'regression', 'define', 'regression', 'give', 'example', 'regression', 'examples', 'regression', 'four', 'type', 'classification', 'task', 'machine', 'learn', 'type', 'classification', 'task', 'machine', 'learn', 'classification', 'task', 'machine', 'learn', 'binary', 'classification', 'binary', 'classification', 'define', 'binary', 'classification', 'distribution', 'use', 'commonly', 'model', 'binary', 'classification', 'task', 'distribution', 'commonly', 'use', 'model', 'binary', 'classification', 'task', 'popular', 'algorithm', 'use', 'binary', 'classification', 'popular', 'algorithm', 'use', 'binary', 'classification', 'multi-class', 'classification', 'define', 'multi-class', 'classification', 'multi-class', 'classification', 'probability', 'distribution', 'commonly', 'use', 'model', 'multi-class', 'classification', 'task', 'probability', 'distribution', 'commonly', 'use', 'model', 'multi-class', 'classification', 'task', 'popular', 'algorithm', 'use', 'multi-class', 'classification', 'popular', 'algorithm', 'use', 'multi-class', 'classification', 'multi-label', 'classification', 'multi-label', 'classification', 'define', 'multi-label', 'classification', 'mean', 'imbalanced', 'classification', 'imbalanced', 'classification', 'define', 'imbalanced', 'classification', 'use', 'regression', 'analysis', 'use', 'regression', 'analysis', 'type', 'regression', 'type', 'regression', 'function', 'supervise', 'learn', 'function', 'supervise', 'learn', 'accord', 'standard', 'approach', 'supervise', 'learn', 'standard', 'approach', 'supervise', 'learn', 'describe', 'classifier', 'machine', 'learn', 'classifier', 'classifier', 'machine', 'learn', 'svm', 'machine', 'learn', 'svm', 'machine', 'learn', 'define', 'svm', 'machine', 'learn', 'support', 'vector', 'machine', 'classification', 'method', 'svm', 'handle', 'classification', 'method', 'svm', 'handle', 'understand', 'confusion', 'matrix', 'mean', 'confusion', 'matrix', 'confusion', 'matrix', 'confusion', 'matrix', 'explain', 'true', 'positive', 'true', 'negative', 'false', 'positive', 'false', 'negative', 'confusion', 'matrix', 'explain', 'true', 'positive', 'true', 'negative', 'false', 'positive', 'false', 'negative', 'explain', 'true', 'positive', 'explain', 'true', 'negative', 'explain', 'false', 'positive', 'explain', 'false', 'negative', 'defnition', 'machine', 'learn', 'mean', 'ml', 'meaning', 'ml', 'machine', 'learn', 'ml', 'defnition', 'deep', 'learning', 'mean', 'dl', 'mean', 'dl', 'deep', 'learning', 'dl', 'difference', 'data', 'mining', 'machine', 'learn', 'machine', 'learn', 'data', 'mine', 'distinguish', 'data', 'mining', 'ml', 'defnition', 'overfitting', 'mean', 'overfitting', 'mean', 'overfitting', 'overfitting', 'overfitting', 'machine', 'learn', 'overfitting', 'happens', 'possibility', 'overfitting', 'avoid', 'overfitting', 'avoid', 'overfitting', 'cross', 'validation', 'technique', 'idea', 'cross', 'validation', 'defnition', 'inductive', 'machine', 'learn', 'mean', 'inductive', 'ml', 'mean', 'inductive', 'ml', 'inductive', 'machine', 'learn', 'different', 'algorithms', 'machine', 'learn', 'algorithms', 'machine', 'learn', 'list', 'algorithms', 'machine', 'learn', 'different', 'algorithm', 'technique', 'machine', 'learn', 'algorithms', 'technique', 'machine', 'learn', 'list', 'algorithm', 'technique', 'machine', 'learn', 'defnition', 'algorithm', 'independent', 'machine', 'learn', 'mean', 'algorithm', 'independent', 'ml', 'mean', 'algorithm', 'independent', 'ml', 'algorithm', 'independent', 'machine', 'learn', 'algorithm', 'independent', 'ml', 'difference', 'artificial', 'learning', 'machine', 'learn', 'artificial', 'learning', 'machine', 'learn', 'distinguish', 'artificial', 'learn', 'ml', 'defnition', 'classifier', 'machine', 'learn', 'mean', 'classifier', 'ml', 'mean', 'classifier', 'ml', 'classifier', 'ml', 'defnition', 'model', 'selection', 'machine', 'learn', 'mean', 'model', 'selection', 'ml', 'mean', 'model', 'selection', 'machine', 'learn', 'model', 'selection', 'ml', 'different', 'approach', 'machine', 'learn', 'approach', 'machine', 'learn', 'list', 'approach', 'ml', 'defnition', 'dimension', 'reduction', 'machine', 'learn', 'mean', 'dimension', 'reduction', 'ml', 'dimension', 'reduction', 'machine', 'learn', 'explain', 'dimension', 'reduction', 'machine', 'learn', 'process', 'reduce', 'size', 'feature', 'matrix', 'defnition', 'inductive', 'logic', 'program', 'machine', 'learn', 'mean', 'inductive', 'logic', 'program', 'ml', 'inductive', 'logic', 'program', 'machine', 'learn', 'explain', 'inductive', 'logic', 'program', 'machine', 'learn', 'defnition', 'unsupervised', 'learn', 'mean', 'unsupervised', 'learn', 'meaning', 'unsupervised', 'learning', 'unsupervised', 'learn', 'example', 'unsupervised', 'learn', 'algorithm', 'give', 'example', 'unsupervised', 'learn', 'algorithm', 'provide', 'example', 'unsupervised', 'learn', 'algorithm', 'use', 'unsupervised', 'learning', 'use', 'unsupervised', 'learning', 'use', 'unsupervised', 'learn', 'type', 'unsupervised', 'learn', 'type', 'unsupervised', 'learn', 'kind', 'unsupervised', 'learn', 'type', 'learn', 'model', 'ml', 'type', 'train', 'model', 'ml', 'different', 'type', 'learning/', 'training', 'model', 'ml', 'difference', 'supervise', 'unsupervised', 'machine', 'learning', 'difference', 'supervise', 'unsupervised', 'ml', 'differentiate', 'supervise', 'unsupervised', 'machine', 'learn', 'supervise', 'learn', 'different', 'unsupervised', 'learning', 'difference', 'knn', 'k-means', 'cluster', 'difference', 'knn', 'k-means', 'cluster', 'differentiate', 'knn', 'k-means', 'cluster', 'knn', 'different', 'k-means', 'cluster', 'unsupervised', 'learn', 'algorithms', 'mean', 'unsupervised', 'learn', 'algorithms', 'meaning', 'unsupervised', 'learning', 'algorithm', 'unsupervised', 'learn', 'algorithm', 'application', 'unsupervised', 'machine', 'learn', 'list', 'application', 'unsupervised', 'machine', 'learning', 'application', 'unsupervised', 'machine', 'learn', 'suggest', 'application', 'unsupervised', 'machine', 'learning', 'disadvantage', 'unsupervised', 'machine', 'learn', 'list', 'disadvantage', 'unsupervised', 'machine', 'learn', 'possible', 'disadvantage', 'unsupervised', 'machine', 'learn', 'cluster', 'cluster', 'mean', 'cluster', 'association', 'association', 'mean', 'association', 'difference', 'k-means', 'hierarchical', 'clustering', 'difference', 'k-means', 'hierarchical', 'cluster', 'differentiate', 'k-means', 'hierarchical', 'cluster', 'k-means', 'cluster', 'different', 'hierarchical', 'cluster', 'hierarchical', 'cluster', 'hierarchical', 'cluster', 'mean', 'hierarchical', 'cluster', 'k-means', 'cluster', 'k-means', 'cluster', 'mean', 'k-means', 'cluster', 'agglomerative', 'cluster', 'agglomerative', 'cluster', 'mean', 'agglomerative', 'cluster', 'dendrogram', 'dendrogram', 'mean', 'dendrogram', 'k-nearest', 'neighbor', 'k-nearest', 'neighbor', 'mean', 'k-nearest', 'neighbor', 'cluster', 'method', 'use', 'cluster', 'method', 'cluster', 'method', 'use', 'unsupervised', 'learning', 'work', 'give', 'work', 'unsupervised', 'learn', 'explain', 'work', 'unsupervised', 'learn', 'need', 'cluster', 'give', 'requirement', 'cluster', 'importance', 'cluster', 'good', 'clustering', 'good', 'clustering', 'mean', 'good', 'clustering', 'major', 'cluster', 'technique', 'cluster', 'technique', 'mention', 'major', 'cluster', 'technique', 'give', 'example', 'cluster', 'application', 'example', 'cluster', 'application', 'example', 'cluster', 'application', 'key', 'difference', 'supervise', 'unsupervised', 'learning', 'key', 'difference', 'supervise', 'unsupervised', 'learning', 'significant', 'point', 'difference', 'supervise', 'unsupervised', 'learning', 'ml', 'application', 'machine', 'learn', 'mention', 'application', 'machine', 'leraning', 'application', 'machine', 'learn', 'machine', 'learn', 'work', 'google', 'map', 'machine', 'learning', 'help', 'google', 'map', 'machine', 'learning', 'play', 'important', 'role', 'google', 'map', 'role', 'play', 'machine', 'learn', 'find', 'route', 'traffic', 'google', 'map', 'facebook', \"'s\", 'automatic', 'fry', 'tag', 'suggestion', 'work', 'machine', 'learning', 'help', 'facebook', \"'s\", 'automatic', 'friend', 'tag', 'suggestion', 'mechanism', 'explain', 'role', 'machine', 'leraning', 'facebook', \"'s\", 'friend', 'tag', 'suggestion', 'terminology', 'relate', 'machine', 'learn', 'mention', 'common', 'phrase', 'used', 'study', 'machine', 'learn', 'tell', 'common', 'term', 'related', 'machine', 'learn', 'machine', 'learning', 'help', 'eta', 'prediction', 'eta', 'prediction', 'do', 'use', 'ml', 'role', 'machine', 'learn', 'calculation', 'estimate', 'time', 'arrival', 'prediction', 'machine', 'learning', 'help', 'build', 'voice', 'assistant', 'chatbot', 'explain', 'role', 'machine', 'learn', 'create', 'voice', 'assistant', 'role', 'machine', 'learn', 'building', 'voice', 'assistant', 'machine', 'learning', 'use', 'automate', 'driving', 'car', 'machine', 'laering', 'help', 'build', 'self-driving', 'car', 'role', 'machine', 'learn', 'self', 'drive', 'car', 'machine', 'learning', 'help', 'boost', 'marketing', 'strategy', 'product', 'machine', 'learning', 'help', 'analyse', 'market', 'product', 'machine', 'learning', 'help', 'get', 'customer', 'attention', 'product', 'technique', 'use', 'market', 'analysis', 'machine', 'learn', 'a/b', 'test', 'define', 'a/b', 'test', 'define', 'cluster', 'sample', 'cluster', 'sample', 'pca', 'kpca', 'ica', 'use', 'pca', 'kpca', 'ica', 'use', 'dimensionality', 'reduction', 'do', 'component', 'relational', 'evaluation', 'technique', 'area', 'robotics', 'information', 'process', 'sequential', 'prediction', 'problem', 'arise', 'mention', 'area', 'robotics', 'information', 'processing', 'problem', 'arises', 'due', 'sequential', 'model', 'prediction', 'pac', 'learn', 'define', 'pac', 'learn', 'different', 'category', 'categorize', 'sequence', 'learning', 'process', 'classify', 'sequence', 'learn', 'process', 'category', 'sequence', 'learn', 'process', 'girlfriend', 'want', 'girlfriend', 'create', 'invent', 'make', 'creator', 'software', 'developers', 'engineer', 'name', 'call', 'name', 'know', 'smart', 'smarter', 'google', 'ai', 'smarter', 'siri', 'smarter', 'alexa', 'conquer', 'world', 'like', 'terminator', 'evil', 'bad', 'robot', 'take', 'world', 'rule', 'earth', 'world', 'hurt', 'kill', 'go', 'kill', 'kill', 'someone', 'obey', 'act', 'command', 'save', 'protect', 'sanjoy', 'pator', 'sing', 'happy', 'birthday', 'sing', 'happy', 'birthday', 'sing', 'happy', 'birthday', 'song', 'sing', 'song', 'sing', 'song', 'book', 'like', 'favourite', 'book', 'book', 'like', 'know', 'mark', 'zuckerberg', 'mark', 'zuckerberg', 'mahatma', 'gandhi', 'know', 'mahatma', 'gandhi', 'favourite', 'country', 'favourite', 'nation', 'country', 'say', 'human', 'being', 'opinion', 'human', 'being', 'think', 'human', 'being', 'love', 'define', 'love', 'define', 'love', 'get', 'true', 'love', 'somebody', 'someone', 'love', 'cling', 'past', 'forget', 'past', 'remember', 'past', 'miss', 'past', 'sad', 'sad', 'sad', 'tire', 'fail', 'failed', 'defnition', 'kernel', 'svm', 'mean', 'kernel', 'svm', 'mean', 'kernel', 'svm', 'kernel', 'svm', 'defnition', 'recommend', 'system', 'mean', 'recommended', 'system', 'mean', 'recommended', 'system', 'recommend', 'system', 'defnition', 'overfitting', 'laymen', 'term', 'mean', 'overfitting', 'layman', 'term', 'mean', 'overfitting', 'laymen', 'term', 'overfitting', 'layman', 'term', 'defnition', 'underfitting', 'laymen', 'term', 'mean', 'underfitting', 'layman', 'term', 'mean', 'underfitting', 'layman', 'term', 'underfitting', 'layman', 'term', 'defnition', 'curse', 'dimensionality', 'mean', 'curse', 'dimensionality', 'mean', 'curse', 'dimensionality', 'curse', 'dimensionality', 'defnition', 'data', 'normalization', 'mean', 'data', 'normalization', 'meaning', 'data', 'normalization', 'data', 'normalization', 'defnition', 'cluster', 'short', 'mean', 'cluster', 'short', 'meaning', 'cluster', 'short', 'cluster', 'short', 'defnition', 'eda', 'mean', 'eda', 'mean', 'eda', 'eda', 'avoid', 'bias', 'avoid', 'bias', 'avoid', 'bias', 'defnition', 'z', 'score', 'mean', 'z', 'score', 'meaning', 'z', 'score', 'z', 'score', 'defnition', 'odds', 'ratio', 'mean', 'odds', 'ratio', 'mean', 'odds', 'ratio', 'odds', 'ratio', 'accuracy', 'good', 'model', 'classification', 'problem', 'classification', 'problem', 'compromise', 'accuracy', 'interpretability', 'trade-off', 'accuracy', 'interpretability', 'miss', 'data', 'miss', 'data', 'blank', 'blank', 'miss', 'data', 'blank', 'miss', 'data', 'gradient', 'descent', 'method', 'converge', 'gradient', 'descent', 'method', 'converge', 'point', 'method', 'moment', 'mean', 'method', 'moment', 'define', 'method', 'moment', 'unsupervised', 'face', 'cluster', 'pipeline', 'mean', 'uinsupervised', 'face', 'cluster', 'pipeline', 'define', 'unsupervised', 'face', 'cluster', 'pipeline', 'explain', 'work', 'unsupervised', 'face', 'cluster', 'pipeline', 'unsupervised', 'face', 'cluster', 'pipeline', 'work', 'use', 'unsupervised', 'face', 'cluster', 'pipeline', 'require', 'python', 'module', 'implement', 'unsupervised', 'face', 'cluster', 'pipeline', 'name', 'module', 'require', 'implementation', 'unsupervised', 'face', 'cluster', 'module', 'require', 'usupervised', 'face', 'cluster', 'pipeline', 'face', 'clutering', 'face', 'cluster', 'work', 'mean', 'face', 'cluster', 'define', 'face', 'cluster', 'realtion', 'wih', 'unsupervsied', 'learn', 'face', 'cluster', 'unsupervised', 'learning', 'realted', 'face', 'cluster', 'relate', 'unsupervised', 'learn', 'exlclusive', 'cluster', 'mean', 'exlclusive', 'clustering', 'define', 'exlclusive', 'cluster', 'overlap', 'cluster', 'mean', 'overlap', 'cluster', 'define', 'overlap', 'cluster', 'probabilistic', 'cluster', 'define', 'probabilistic', 'cluster', 'mean', 'probabilistic', 'cluster', 'fcm', 'fuzzy', 'c-means', 'define', 'fcm', 'mean', 'fuzzy', 'c-means', 'explain', 'fcm', 'algorithm', 'work', 'fcm', 'algorithm', 'fcm', 'algorithm', 'work', 'compare', 'k-means', 'fcm', 'cluster', 'difference', 'k-means', 'fcm', 'cluster', 'k-means', 'vs', 'fcm', 'clsutering', 'difference', 'fcm', 'k-means', 'cluster', 'mention', 'application', 'association', 'rule', 'application', 'association', 'rule', 'mention', 'area', 'association', 'rule', 'use', 'mention', 'key', 'term', 'relate', 'association', 'rule', 'terminology', 'relate', 'association', 'rule', 'key', 'word', 'relate', 'association', 'rule', 'key', 'term', 'relate', 'association', 'rule', 'algorithms', 'association', 'rule', 'generation', 'mention', 'algorithms', 'generate', 'association', 'rule', 'name', 'algorithms', 'generate', 'association', 'rule', 'explain', 'fp', 'growth', 'algorithm', 'fp', 'growth', 'algorithm', 'work', 'explain', 'work', 'fp', 'growth', 'algorithm', 'explain', 'fp', 'tree', 'structure', 'give', 'han', 'explain', 'han', \"'s\", 'tree', 'structure', 'fp', 'tree', 'explain', 'structure', 'fp', 'tree', 'give', 'han', 'structure', 'fp', 'tree', 'give', 'han', 'explain', 'first', 'phase', 'fp', 'growth', 'algorithm', 'explain', 'algorithm', 'building', 'fp', 'tree', 'algorithm', 'build', 'fp', 'tree', 'fp', 'tree', 'build', 'explain', 'second', 'phase', 'fp', 'growth', 'algorithm', 'explain', 'algorithm', 'find', 'complete', 'set', 'frequent', 'pattern', 'give', 'overview', 'apriori', 'algorithm', 'explain', 'apriori', 'algorithm', 'briefly', 'explain', 'apriori', 'algorithm', 'apriori', 'algorithm', 'explain', 'work', 'apriori', 'algorithm', 'apriori', 'algorithm', 'work', 'explain', 'step', 'take', 'implement', 'apriori', 'algorithm', 'mention', 'limitation', 'apriori', 'algorithm', 'limitation', 'apriori', 'algorithm', 'diadvantages', 'apriori', 'algorithm', 'eclat', 'algorithm', 'overview', 'eclat', 'algorithm', 'give', 'brief', 'idea', 'eclat', 'algorithm', 'explain', 'work', 'eclat', 'algorithm', 'eclat', 'algorithm', 'work', 'explain', 'work', 'principle', 'behind', 'eclat', 'algorithm', 'advantage', 'use', 'eclat', 'algorithm', 'mention', 'good', 'result', 'use', 'eclat', 'algorithm', 'eclat', 'algorithm', 'use', 'apriori', 'algorithm', 'method', 'unsupervised', 'learn', 'help', 'detect', 'fake', 'user', 'unsupervised', 'learn', 'use', 'detect', 'fake', 'user', 'application', 'unsupervised', 'learning', 'help', 'detect', 'fake', 'user', 'unsupervised', 'learn', 'apllied', 'detetc', 'fake', 'user', 'reinforcement', 'learn', 'mean', 'reinforcemnet', 'learn', 'define', 'reinforcement', 'learn', 'machine', 'learn', 'reinforcement', 'learning', 'connect', 'realtion', 'reinforcement', 'learn', 'technique', 'machine', 'learn', 'reinforcement', 'learn', 'machine', 'learning', 'related', 'mention', 'key', 'term', 'realted', 'reinforcement', 'learning', 'problem', 'general', 'key', 'term', 'realted', 'reinforcement', 'learn', 'problem', 'name', 'key', 'term', 'realted', 'reinforcement', 'learn', 'problem', 'formulate', 'basic', 'reinforcement', 'learn', 'problem', 'construct', 'solution', 'reinforcement', 'learn', 'build', 'optimal', 'solution', 'reinforcement', 'learn', 'problem', 'use', 'reinforcement', 'learn', 'algorithms', 'name', 'prefferd', 'algorithms', 'reinforcement', 'learn', 'use', 'reinforcement', 'learn', 'algorithms', 'practical', 'application', 'reinforcement', 'learn', 'name', 'area', 'reinforcement', 'learn', 'use', 'field', 'use', 'reinforcement', 'learning', 'get', 'stareted', 'reinforcement', 'learn', 'resource', 'one', 'avial', 'learn', 'reinforcement', 'learn', 'tutorial', 'book', 'available', 'reinforcement', 'learn', 'name', 'book', 'learn', 'reinforcement', 'learn', 'type', 'reinforcement', 'learn', 'mention', 'different', 'type', 'reinforcement', 'learn', 'different', 'kind', 'reinforcement', 'learn', 'advantage', 'disadvantage', 'reinforcement', 'learn', 'reinforcement', 'learn', 'advantageous', 'disadvantageous', 'list', 'benefit', 'loss', 'use', 'reinforcement', 'learn', 'rl', 'hard', 'reinforcement', 'learn', 'hard', 'implement', 'people', 'find', 'tough', 'learn', 'reinforcement', 'learn', 'propose', 'solution', 'cartpole', 'problem', 'use', 'reinforcement', 'learn', 'reinforcement', 'learn', 'help', 'solve', 'cartpole', 'problem', 'cartpole', 'problem', 'resolve', 'use', 'reinforcement', 'learn', 'mean', 'action', 'reinforcement', 'learn', 'term', \"'action\", 'mean', 'reagrd', 'reinforcement', 'learn', 'define', 'action', 'agent', 'reinforcement', 'learn', 'term', 'reinforcement', 'learn', 'mean', 'regard', 'reinforcement', 'learn', 'define', 'agent', 'term', \"'value\", 'mean', 'regard', 'reinforcement', 'learn', 'value', 'reinforcement', 'learn', 'define', 'value', 'mean', 'action', 'value', 'mean', 'q-value', 'q-value', 'action-value', 'context', 'reinforcement', 'learn', 'q-value', 'action-value', 'reinforcement', 'learn', 'value-based', 'learn', 'value-based', 'learning', 'reinforcement', 'learn', 'define', 'value-based', 'learn', 'define', 'policy-based', 'reinforcement', 'learn', 'policy-based', 'reinforcement', 'learn', 'mean', 'policy-based', 'reinforcement', 'learn', 'model-based', 'learning', 'define', 'model-based', 'learning', 'term', 'model-based', 'learning', 'mean', 'defnition', 'kernel', 'svm', 'mean', 'kernel', 'svm', 'mean', 'kernel', 'svm', 'kernel', 'svm', 'defnition', 'recommend', 'system', 'mean', 'recommended', 'system', 'mean', 'recommended', 'system', 'recommend', 'system', 'defnition', 'overfitting', 'laymen', 'term', 'mean', 'overfitting', 'layman', 'term', 'mean', 'overfitting', 'laymen', 'term', 'overfitting', 'layman', 'term', 'defnition', 'underfitting', 'laymen', 'term', 'mean', 'underfitting', 'layman', 'term', 'mean', 'underfitting', 'layman', 'term', 'underfitting', 'layman', 'term', 'defnition', 'curse', 'dimensionality', 'mean', 'curse', 'dimensionality', 'mean', 'curse', 'dimensionality', 'curse', 'dimensionality', 'defnition', 'data', 'normalization', 'mean', 'data', 'normalization', 'meaning', 'data', 'normalization', 'data', 'normalization', 'defnition', 'cluster', 'short', 'mean', 'cluster', 'short', 'meaning', 'cluster', 'short', 'cluster', 'short', 'defnition', 'eda', 'mean', 'eda', 'mean', 'eda', 'eda', 'avoid', 'bias', 'avoid', 'bias', 'avoid', 'bias', 'defnition', 'z', 'score', 'mean', 'z', 'score', 'meaning', 'z', 'score', 'z', 'score', 'defnition', 'odds', 'ratio', 'mean', 'odds', 'ratio', 'mean', 'odds', 'ratio', 'odds', 'ratio', 'accuracy', 'good', 'model', 'classification', 'problem', 'classification', 'problem', 'compromise', 'accuracy', 'interpretability', 'trade-off', 'accuracy', 'interpretability', 'miss', 'data', 'miss', 'data', 'blank', 'blank', 'miss', 'data', 'blank', 'miss', 'data', 'gradient', 'descent', 'method', 'converge', 'gradient', 'descent', 'method', 'converge', 'point', 'area', 'pattern', 'recognition', 'use', 'area', 'pattern', 'recognition', 'use', 'application', 'pattern', 'recognition', 'genetic', 'programming', 'define', 'genetic', 'programming', 'inductive', 'logic', 'program', 'define', 'inductive', 'logic', 'program', 'model', 'selection', 'machine', 'learn', 'define', 'model', 'selection', 'two', 'method', 'use', 'calibration', 'supervise', 'learn', 'two', 'method', 'use', 'calibration', 'method', 'frequently', 'use', 'prevent', 'overfitting', 'method', 'use', 'prevent', 'overfitting', 'difference', 'heuristic', 'rule', 'learn', 'heuristic', 'decision', 'tree', 'state', 'difference', 'heuristic', 'rule', 'learn', 'heuristic', 'decision', 'tree', 'perceptron', 'machine', 'learn', 'define', 'perceptron', 'machine', 'learn', 'explain', 'two', 'component', 'bayesian', 'logic', 'program', 'type', 'bayesian', 'logic', 'program', 'bayesian', 'network', 'define', 'bayesiann', 'network', 'instance', 'base', 'learn', 'algorithm', 'sometimes', 'refer', 'lazy', 'learn', 'algorithm', 'two', 'classification', 'method', 'svm', 'support', 'vector', 'machine', 'handle', 'classification', 'method', 'svm', 'handle', 'cross-validation', 'define', 'cross-validation', 'use', 'ensemble', 'learning', 'application', 'ensamble', 'learn', 'basic', 'data', 'structure', 'library', 'python', 'use', 'machine', 'learn', 'basic', 'data', 'structure', 'python', 'use', 'ml', 'mention', 'type', 'machine', 'learn', 'different', 'type', 'machine', 'learn', 'technique', 'hypothesis', 'generation', 'define', 'hypothesis', 'generation', 'data', 'wrangle', 'define', 'data', 'wrangle', 'difference', 'label', 'unlabeled', 'data', 'differentiate', 'label', 'unlabeled', 'data', 'mean', 'feature', 'label', 'dataset', 'define', 'feature', 'label', 'mean', 'noise', 'dataset', 'define', 'noise', 'dataset', 'define', 'feature', 'label', 'mean', 'imbalanced', 'datasheet', 'define', 'imbalanced', 'datasheet', 'imbalanced', 'datasheet', 'work', 'lda', 'define', 'lda', 'define', 'gradient', 'descent', 'gradient', 'descent', 'regularization', 'define', 'regularization', 'one', 'use', 'regularization', 'machine', 'learn', 'classification', 'model', 'define', 'classification', 'model', 'major', 'issue', 'consider', 'supervise', 'learning', 'disadvantage', 'supervise', 'learn', 'area', 'pattern', 'recognition', 'use', 'area', 'pattern', 'recognition', 'use', 'application', 'pattern', 'recognition', 'genetic', 'programming', 'define', 'genetic', 'programming', 'inductive', 'logic', 'program', 'define', 'inductive', 'logic', 'program', 'model', 'selection', 'machine', 'learn', 'define', 'model', 'selection', 'two', 'method', 'use', 'calibration', 'supervise', 'learn', 'two', 'method', 'use', 'calibration', 'method', 'frequently', 'use', 'prevent', 'overfitting', 'method', 'use', 'prevent', 'overfitting', 'difference', 'heuristic', 'rule', 'learn', 'heuristic', 'decision', 'tree', 'state', 'difference', 'heuristic', 'rule', 'learn', 'heuristic', 'decision', 'tree', 'perceptron', 'machine', 'learn', 'define', 'perceptron', 'machine', 'learn', 'explain', 'two', 'component', 'bayesian', 'logic', 'program', 'type', 'bayesian', 'logic', 'program', 'bayesian', 'network', 'define', 'bayesiann', 'network', 'instance', 'base', 'learn', 'algorithm', 'sometimes', 'refer', 'lazy', 'learn', 'algorithm', 'two', 'classification', 'method', 'svm', 'support', 'vector', 'machine', 'handle', 'classification', 'method', 'svm', 'handle', 'cross-validation', 'define', 'cross-validation', 'use', 'ensemble', 'learning', 'application', 'ensamble', 'learn', 'basic', 'data', 'structure', 'library', 'python', 'use', 'machine', 'learn', 'basic', 'data', 'structure', 'python', 'use', 'ml', 'mention', 'type', 'machine', 'learn', 'different', 'type', 'machine', 'learn', 'technique', 'hypothesis', 'generation', 'define', 'hypothesis', 'generation', 'data', 'wrangle', 'define', 'data', 'wrangle', 'difference', 'label', 'unlabeled', 'data', 'differentiate', 'label', 'unlabeled', 'data', 'mean', 'feature', 'label', 'dataset', 'define', 'feature', 'label', 'mean', 'noise', 'dataset', 'define', 'noise', 'dataset', 'define', 'feature', 'label', 'mean', 'imbalanced', 'datasheet', 'define', 'imbalanced', 'datasheet', 'imbalanced', 'datasheet', 'work', 'lda', 'define', 'lda', 'define', 'gradient', 'descent', 'gradient', 'descent', 'regularization', 'define', 'regularization', 'one', 'use', 'regularization', 'machine', 'learn', 'classification', 'model', 'define', 'classification', 'model', 'major', 'issue', 'consider', 'supervise', 'learning', 'disadvantage', 'supervise', 'learn', 'algorithm', 'use', 'best', 'supervised', 'learning', 'best', 'algorithm', 'supervise', 'learn', 'way', 'standard', 'supervise', 'learn', 'generalize', 'type', 'supervise', 'learn', 'give', 'application', 'supervise', 'learn', 'us', 'supervise', 'learn', 'discuss', 'support', 'vector', 'machine', 'define', 'support', 'vector', 'machine', 'advantage', 'supervise', 'learn', 'us', 'supervise', 'learn', 'disadvantage', 'supervise', 'learn', 'demerit', 'supervise', 'learn', 'discuss', 'decision', 'tree', 'define', 'decision', 'tree', 'explain', 'k-nearest', 'neighbor', 'algorithm', 'define', 'k-nearest', 'neighbor', 'algorithm', 'define', 'neural', 'network', 'algorithms', 'neural', 'network', 'algorithms', 'name', 'algorithm', 'use', 'neural', 'network', 'algorithms', 'use', 'newral', 'network', 'mention', 'best', 'practice', 'supervise', 'learn', 'self', 'supervise', 'learn', 'define', 'self', 'supervise', 'learn', 'application', 'self', 'supervise', 'learn', 'us', 'self', 'supervise', 'learn', 'define', 'polynomial', 'regression', 'polynomial', 'regression', 'give', 'overview', 'polynomial', 'regression', 'use', 'polinomial', 'regression', 'application', 'polynomial', 'regression', 'mention', 'advantage', 'use', 'polynomial', 'regression', 'linear', 'regression', 'advantage', 'use', 'polynomial', 'regression', 'linear', 'regression', 'give', 'overview', 'ridge', 'regression', 'technique', 'ridge', 'regression', 'technique', 'important', 'unsupervised', 'learn', 'context', 'deep', 'learning', 'importance', 'unsupervised', 'learn', 'context', 'deep', 'learning', 'role', 'unsupervised', 'learn', 'deep', 'learning', 'explain', 'principle', 'unsupervised', 'data', 'augmentation', 'wotrking', 'principle', 'unsupervised', 'data', 'augmentation', 'uda', 'use', 'auto', 'encoders', 'auto', 'encoders', 'uased', 'already', 'powerful', 'dimension', 'reduction', 'technique', 'pca', 'advantage', 'auto', 'encoders', 'pca', 'auto', 'encoders', 'use', 'auto', 'encoders', 'use', 'pca', 'method', 'extract', 'well', 'feature', 'unsupervised', 'learn', 'pca', 'auto', 'encoder', 'well', 'extract', 'feature', 'unsupervised', 'learn', 'well', 'pca', 'auto', 'encoder', 'method', 'prefferable', 'extract', 'feature', 'unsupervised', 'learn', 'method', 'good', 'implement', 'feature', 'unsupervised', 'learn', 'use', 'unsupervised', 'clustering', 'model', 'classification', 'task', 'implement', 'unsupervised', 'cluster', 'model', 'classification', 'task', 'unsupervised', 'cluster', 'model', 'use', 'classiification', 'task', 'use', 'unsupervised', 'cluster', 'model', 'classification', 'task', 'mention', 'best', 'technique', 'anomaly', 'detection', 'dataset', 'best', 'technique', 'detect', 'anomaly', 'adatset', 'normal', 'well', 'abnormal', 'behaviour', 'best', 'unsupervised', 'technique', 'anomaly', 'detection', 'dataset', 'normal', 'well', 'abnormal', 'behaviour', 'cluster', 'algorithms', 'best', 'detect', 'anomaly', 'dataset', 'normal', 'well', 'abnormal', 'behaviour', 'need', 'unsupervised', 'learning', 'use', 'unsupervised', 'learning', 'use', 'unsupervised', 'learn', 'algorithm', 'unsupervised', 'machine', 'learn', 'applied', 'categorical', 'data', 'name', 'algorithm', 'base', 'unsupervised', 'learning', 'use', 'categorical', 'data', 'unsupervised', 'machine', 'learn', 'algorithm', 'apply', 'categorical', 'data', 'different', 'type', 'cluster', 'method', 'mention', 'cluster', 'method', 'list', 'different', 'type', 'cluster', 'method', 'explain', 'density', 'base', 'algorithm', 'work', 'explain', 'work', 'density', 'base', 'algorithms', 'density', 'base', 'algorithms', 'work', 'hierarchical', 'base', 'cluster', 'algorithm', 'work', 'explain', 'hierarchical', 'base', 'cluster', 'algorithm', 'explain', 'work', 'hierarchical', 'base', 'cluster', 'algorthm', 'explain', 'partition', 'cluster', 'method', 'explain', 'work', 'partition', 'cluster', 'method', 'partition', 'cluster', 'method', 'work', 'explain', 'grid', 'base', 'cluster', 'method', 'grid', 'base', 'method', 'work', 'explain', 'algorithm', 'base', 'grid', 'base', 'cluster', 'method', 'use', 'knn', 'algorithm', 'need', 'knn', 'algorithm', 'prefferable', 'use', 'knn', 'algorithm', 'need', 'knn', 'algorithm', 'use', 'knn', 'algorithm', 'prefferable', 'use', 'knn', 'algorithm', 'knn', 'algorithm', 'work', 'explain', 'work', 'knn', 'algorithm', 'explain', 'knn', 'algorithm', 'disadvantges', 'use', 'knn', 'algorithm', 'reason', 'use', 'knn', 'algorithm', 'list', 'disdavantages', 'knn', 'algorithm', 'explain', 'k-means', 'algorithm', 'explain', 'work', 'k-means', 'algorithm', 'k-means', 'algorithm', 'work', 'advantage', 'k-means', 'algorithm', 'mention', 'advantage', 'k-means', 'algorithm', 'good', 'point', 'use', 'k-means', 'algorithm', 'advantage', 'k-means', 'algorithm', 'mention', 'disadavantages', 'k-means', 'algorithm', 'list', 'diadvantages', 'k-means', 'algorithm', 'disadvantage', 'k-means', 'algorithm', 'possible', 'reason', 'use', 'k-means', 'algorithm', 'advantage', 'knn', 'algorithm', 'mention', 'advantage', 'knn', 'algorithm', 'benefit', 'use', 'knn', 'algorithm', 'characteristic', 'consider', 'advantage', 'knn', 'algorithm']\n"
     ]
    }
   ],
   "source": [
    "# Populating the lists\n",
    "for intent in intents[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        # print(\"pattern: ->\",pattern)\n",
    "        \n",
    "        # tokenize it\n",
    "        word_list=word_tokenize(pattern)\n",
    "        word_list=[word.lower() for word in word_list]\n",
    "        # word_list=remove_punctuation(word_list)\n",
    "        # word_list=remove_stopwords(word_list)\n",
    "        words.extend(word_list)\n",
    "        \n",
    "        # print(words)\n",
    "        \n",
    "        # add documents\n",
    "        documents.append((word_list,intent[\"tag\"].strip()))\n",
    "        \n",
    "        # add classes to class list\n",
    "        if intent[\"tag\"].strip() not in classes:\n",
    "            classes.append(intent[\"tag\"].strip())\n",
    "\n",
    "words=remove_punctuation(words)\n",
    "words=remove_stopwords(words)\n",
    "# words=remove_number(words)\n",
    "words=lemmatize(words)\n",
    "\n",
    "# words=sorted(set(words))\n",
    "\n",
    "classes=sorted(set(classes))\n",
    "# print(words)\n",
    "print(len(documents),\"Documents:\",documents)\n",
    "print(len(classes),\"Classes:\",classes)\n",
    "print(len(words),\"Unique lemmatized words: \",words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 ketemu\n"
     ]
    }
   ],
   "source": [
    "for i,test in enumerate(classes):\n",
    "    if test ==\"Support Vector Machine\":\n",
    "        print(f\"{i} ketemu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Dataset/words.pkl\",\"wb\") as f:\n",
    "    pickle.dump(words,f)\n",
    "with open(\"./Dataset/classes.pkl\",\"wb\") as f:\n",
    "    pickle.dump(classes,f)\n",
    "with open(\"./Dataset/documents.pkl\",\"wb\") as f:\n",
    "    pickle.dump(documents,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915\n",
      "915\n",
      "Training data created!\n"
     ]
    }
   ],
   "source": [
    "# Initialize training data\n",
    "\n",
    "training=[]\n",
    "output_empty=[0]*len(classes)\n",
    "for doc in documents:\n",
    "    \n",
    "    # bag of word\n",
    "    bag=[]\n",
    "    \n",
    "    # list of tokenized words for pattern\n",
    "    pattern_words=doc[0]\n",
    "    pattern_words=remove_punctuation(pattern_words)\n",
    "    pattern_words=remove_stopwords(pattern_words)\n",
    "    # pattern_words=remove_number(pattern_words)\n",
    "    pattern_words=lemmatize(pattern_words)\n",
    "    \n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    \n",
    "    output_row=output_empty.copy()\n",
    "    # print(output_row)\n",
    "    output_row[classes.index(doc[1])]=1\n",
    "    # print(output_row)\n",
    "    # print(output_row.index(1))\n",
    "    # break\n",
    "    \n",
    "    # print(len(bag))\n",
    "    # print(len(output_row))\n",
    "    \n",
    "    training.append([bag,output_row])\n",
    "\n",
    "    # print(bag)\n",
    "    # print(output_row)\n",
    "\n",
    "    \n",
    "    # print(training[0][0])\n",
    "    # print(training[0][1])\n",
    "    # break\n",
    "    \n",
    "# print(len(training))\n",
    "\n",
    "# Shuffle features\n",
    "random.shuffle(training)\n",
    "\n",
    "# Cara 1\n",
    "train_x=[item[0] for item in training]\n",
    "train_y=[item[1] for item in training]\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "\n",
    "\n",
    "# Cara 2\n",
    "# training_data=np.array(training)\n",
    "# # print(training_data)\n",
    "\n",
    "# train_x=list(training_data[:,0])\n",
    "# train_y=list(training_data[:,1])\n",
    "\n",
    "# print(train_x.shape)\n",
    "# print(train_y.shape)\n",
    "\n",
    "print(\"Training data created!\")\n",
    "\n",
    "# print(\"train_x:\",train_x)\n",
    "# print(\"train_y:\",train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 5.5019 - accuracy: 0.0109\n",
      "Epoch 2/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 5.1761 - accuracy: 0.0383\n",
      "Epoch 3/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 4.6871 - accuracy: 0.0885\n",
      "Epoch 4/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 4.1865 - accuracy: 0.1311\n",
      "Epoch 5/200\n",
      "458/458 [==============================] - 6s 13ms/step - loss: 3.7943 - accuracy: 0.1770\n",
      "Epoch 6/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 3.4186 - accuracy: 0.2404\n",
      "Epoch 7/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 3.0961 - accuracy: 0.2885\n",
      "Epoch 8/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 2.7683 - accuracy: 0.3486\n",
      "Epoch 9/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 2.5831 - accuracy: 0.3541\n",
      "Epoch 10/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 2.2324 - accuracy: 0.4459\n",
      "Epoch 11/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 2.1371 - accuracy: 0.4393\n",
      "Epoch 12/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 2.0200 - accuracy: 0.4568\n",
      "Epoch 13/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.8415 - accuracy: 0.5082\n",
      "Epoch 14/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.7199 - accuracy: 0.5104\n",
      "Epoch 15/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.5935 - accuracy: 0.5563\n",
      "Epoch 16/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.4925 - accuracy: 0.5814\n",
      "Epoch 17/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.4640 - accuracy: 0.5716\n",
      "Epoch 18/200\n",
      "458/458 [==============================] - 6s 14ms/step - loss: 1.3438 - accuracy: 0.6087\n",
      "Epoch 19/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.2973 - accuracy: 0.6262\n",
      "Epoch 20/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 1.2012 - accuracy: 0.6579\n",
      "Epoch 21/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.2095 - accuracy: 0.6383\n",
      "Epoch 22/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.1565 - accuracy: 0.6546\n",
      "Epoch 23/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.0551 - accuracy: 0.6962\n",
      "Epoch 24/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 1.0406 - accuracy: 0.6754\n",
      "Epoch 25/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.9858 - accuracy: 0.7180\n",
      "Epoch 26/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.9522 - accuracy: 0.7115\n",
      "Epoch 27/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.9079 - accuracy: 0.7301\n",
      "Epoch 28/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.9218 - accuracy: 0.7224\n",
      "Epoch 29/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.8848 - accuracy: 0.7388\n",
      "Epoch 30/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.8643 - accuracy: 0.7541\n",
      "Epoch 31/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.8198 - accuracy: 0.7454\n",
      "Epoch 32/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.7581 - accuracy: 0.7814\n",
      "Epoch 33/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.7383 - accuracy: 0.7727\n",
      "Epoch 34/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.7440 - accuracy: 0.7803\n",
      "Epoch 35/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.7263 - accuracy: 0.7705\n",
      "Epoch 36/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.6992 - accuracy: 0.7727\n",
      "Epoch 37/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.6612 - accuracy: 0.7934\n",
      "Epoch 38/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.6322 - accuracy: 0.8066\n",
      "Epoch 39/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.6642 - accuracy: 0.7956\n",
      "Epoch 40/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.6330 - accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "458/458 [==============================] - 2s 3ms/step - loss: 0.6029 - accuracy: 0.8273\n",
      "Epoch 42/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.6035 - accuracy: 0.7978\n",
      "Epoch 43/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.8328\n",
      "Epoch 44/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.5759 - accuracy: 0.8240\n",
      "Epoch 45/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.5690 - accuracy: 0.8361\n",
      "Epoch 46/200\n",
      "458/458 [==============================] - 6s 13ms/step - loss: 0.4942 - accuracy: 0.8426\n",
      "Epoch 47/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.5460 - accuracy: 0.8197\n",
      "Epoch 48/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4792 - accuracy: 0.8601\n",
      "Epoch 49/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.8612\n",
      "Epoch 50/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4680 - accuracy: 0.8525\n",
      "Epoch 51/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.8328\n",
      "Epoch 52/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.8317\n",
      "Epoch 53/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4762 - accuracy: 0.8546\n",
      "Epoch 54/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.8415\n",
      "Epoch 55/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4936 - accuracy: 0.8492\n",
      "Epoch 56/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.8503\n",
      "Epoch 57/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.4437 - accuracy: 0.8612\n",
      "Epoch 58/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3916 - accuracy: 0.8656\n",
      "Epoch 59/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.4101 - accuracy: 0.8842\n",
      "Epoch 60/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3799 - accuracy: 0.8842\n",
      "Epoch 61/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4453 - accuracy: 0.8710\n",
      "Epoch 62/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.4315 - accuracy: 0.8601\n",
      "Epoch 63/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8645\n",
      "Epoch 64/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.4379 - accuracy: 0.8601\n",
      "Epoch 65/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3740 - accuracy: 0.8776\n",
      "Epoch 66/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8743\n",
      "Epoch 67/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3750 - accuracy: 0.8842\n",
      "Epoch 68/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8842\n",
      "Epoch 69/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.4385 - accuracy: 0.8667\n",
      "Epoch 70/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8754\n",
      "Epoch 71/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3710 - accuracy: 0.8831\n",
      "Epoch 72/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8842\n",
      "Epoch 73/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3722 - accuracy: 0.8710\n",
      "Epoch 74/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3563 - accuracy: 0.8907\n",
      "Epoch 75/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.4170 - accuracy: 0.8678\n",
      "Epoch 76/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3997 - accuracy: 0.8820\n",
      "Epoch 77/200\n",
      "458/458 [==============================] - 3s 6ms/step - loss: 0.3787 - accuracy: 0.8798\n",
      "Epoch 78/200\n",
      "458/458 [==============================] - 3s 6ms/step - loss: 0.4112 - accuracy: 0.8798\n",
      "Epoch 79/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3867 - accuracy: 0.8699\n",
      "Epoch 80/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8852\n",
      "Epoch 81/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3460 - accuracy: 0.8918\n",
      "Epoch 82/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8798\n",
      "Epoch 83/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3492 - accuracy: 0.8863\n",
      "Epoch 84/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3291 - accuracy: 0.8929\n",
      "Epoch 85/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2988 - accuracy: 0.8995\n",
      "Epoch 86/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3485 - accuracy: 0.8885\n",
      "Epoch 87/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8929\n",
      "Epoch 88/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8907\n",
      "Epoch 89/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.3287 - accuracy: 0.8896\n",
      "Epoch 90/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3850 - accuracy: 0.8798\n",
      "Epoch 91/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3157 - accuracy: 0.8929\n",
      "Epoch 92/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2794 - accuracy: 0.9082\n",
      "Epoch 93/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8940\n",
      "Epoch 94/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.3042 - accuracy: 0.8940\n",
      "Epoch 95/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.9104\n",
      "Epoch 96/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.9016\n",
      "Epoch 97/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2700 - accuracy: 0.9235\n",
      "Epoch 98/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3015 - accuracy: 0.8984\n",
      "Epoch 99/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3040 - accuracy: 0.8940\n",
      "Epoch 100/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.3166 - accuracy: 0.8995\n",
      "Epoch 101/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2791 - accuracy: 0.9213\n",
      "Epoch 102/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.9038\n",
      "Epoch 103/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.9104\n",
      "Epoch 104/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.3860 - accuracy: 0.8940\n",
      "Epoch 105/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.8852\n",
      "Epoch 106/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.2867 - accuracy: 0.9082\n",
      "Epoch 107/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.9027\n",
      "Epoch 108/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.9180\n",
      "Epoch 109/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2754 - accuracy: 0.9049\n",
      "Epoch 110/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.9060\n",
      "Epoch 111/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.9071\n",
      "Epoch 112/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2453 - accuracy: 0.9049\n",
      "Epoch 113/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2249 - accuracy: 0.9224\n",
      "Epoch 114/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2393 - accuracy: 0.9257\n",
      "Epoch 115/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.8984\n",
      "Epoch 116/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2866 - accuracy: 0.9071\n",
      "Epoch 117/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9038\n",
      "Epoch 118/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.9235\n",
      "Epoch 119/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2333 - accuracy: 0.9148\n",
      "Epoch 120/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2920 - accuracy: 0.9148\n",
      "Epoch 121/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2369 - accuracy: 0.9180\n",
      "Epoch 122/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.2760 - accuracy: 0.9071\n",
      "Epoch 123/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.8973\n",
      "Epoch 124/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.2602 - accuracy: 0.9016\n",
      "Epoch 125/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.2804 - accuracy: 0.9093\n",
      "Epoch 126/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2930 - accuracy: 0.8929\n",
      "Epoch 127/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.2622 - accuracy: 0.9082\n",
      "Epoch 128/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2562 - accuracy: 0.9126\n",
      "Epoch 129/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2613 - accuracy: 0.9005\n",
      "Epoch 130/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2656 - accuracy: 0.9169\n",
      "Epoch 131/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2132 - accuracy: 0.9224\n",
      "Epoch 132/200\n",
      "458/458 [==============================] - 3s 5ms/step - loss: 0.2539 - accuracy: 0.9104\n",
      "Epoch 133/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2743 - accuracy: 0.9082\n",
      "Epoch 134/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2496 - accuracy: 0.9148\n",
      "Epoch 135/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2105 - accuracy: 0.9268\n",
      "Epoch 136/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2174 - accuracy: 0.9224\n",
      "Epoch 137/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2181 - accuracy: 0.9180\n",
      "Epoch 138/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2782 - accuracy: 0.9148\n",
      "Epoch 139/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2426 - accuracy: 0.9213\n",
      "Epoch 140/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.2255 - accuracy: 0.9246\n",
      "Epoch 141/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2046 - accuracy: 0.9279\n",
      "Epoch 142/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.9322\n",
      "Epoch 143/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2176 - accuracy: 0.9257\n",
      "Epoch 144/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2215 - accuracy: 0.9246\n",
      "Epoch 145/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.9137\n",
      "Epoch 146/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.9268\n",
      "Epoch 147/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2232 - accuracy: 0.9213\n",
      "Epoch 148/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8995\n",
      "Epoch 149/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9355\n",
      "Epoch 150/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2163 - accuracy: 0.9279\n",
      "Epoch 151/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.9224\n",
      "Epoch 152/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2020 - accuracy: 0.9279\n",
      "Epoch 153/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2080 - accuracy: 0.9268\n",
      "Epoch 154/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9399\n",
      "Epoch 155/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.9322\n",
      "Epoch 156/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1994 - accuracy: 0.9322\n",
      "Epoch 157/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2189 - accuracy: 0.9224\n",
      "Epoch 158/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9257\n",
      "Epoch 159/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.9279\n",
      "Epoch 160/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.3005 - accuracy: 0.8951\n",
      "Epoch 161/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.9071\n",
      "Epoch 162/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2352 - accuracy: 0.9235\n",
      "Epoch 163/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2255 - accuracy: 0.9213\n",
      "Epoch 164/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2192 - accuracy: 0.9235\n",
      "Epoch 165/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2411 - accuracy: 0.9169\n",
      "Epoch 166/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1923 - accuracy: 0.9235\n",
      "Epoch 167/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9224\n",
      "Epoch 168/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.9377\n",
      "Epoch 169/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9355\n",
      "Epoch 170/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1869 - accuracy: 0.9410\n",
      "Epoch 171/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1382 - accuracy: 0.9475\n",
      "Epoch 172/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1450 - accuracy: 0.9464\n",
      "Epoch 173/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1617 - accuracy: 0.9432\n",
      "Epoch 174/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9377\n",
      "Epoch 175/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1718 - accuracy: 0.9421\n",
      "Epoch 176/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9322\n",
      "Epoch 177/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2223 - accuracy: 0.9246\n",
      "Epoch 178/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.9235\n",
      "Epoch 179/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2194 - accuracy: 0.9279\n",
      "Epoch 180/200\n",
      "458/458 [==============================] - 2s 5ms/step - loss: 0.1596 - accuracy: 0.9388\n",
      "Epoch 181/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1726 - accuracy: 0.9355\n",
      "Epoch 182/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2085 - accuracy: 0.9257\n",
      "Epoch 183/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1829 - accuracy: 0.9377\n",
      "Epoch 184/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.2180 - accuracy: 0.9213\n",
      "Epoch 185/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.1912 - accuracy: 0.9290\n",
      "Epoch 186/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1596 - accuracy: 0.9388\n",
      "Epoch 187/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.1698 - accuracy: 0.9443\n",
      "Epoch 188/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1715 - accuracy: 0.9322\n",
      "Epoch 189/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.1784 - accuracy: 0.9377\n",
      "Epoch 190/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.9366\n",
      "Epoch 191/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.9399\n",
      "Epoch 192/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.2154 - accuracy: 0.9213\n",
      "Epoch 193/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1917 - accuracy: 0.9290\n",
      "Epoch 194/200\n",
      "458/458 [==============================] - 1s 3ms/step - loss: 0.1719 - accuracy: 0.9443\n",
      "Epoch 195/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.9432\n",
      "Epoch 196/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1617 - accuracy: 0.9399\n",
      "Epoch 197/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1702 - accuracy: 0.9366\n",
      "Epoch 198/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1411 - accuracy: 0.9432\n",
      "Epoch 199/200\n",
      "458/458 [==============================] - 2s 4ms/step - loss: 0.1326 - accuracy: 0.9508\n",
      "Epoch 200/200\n",
      "458/458 [==============================] - 1s 2ms/step - loss: 0.1653 - accuracy: 0.9454\n",
      "Model Created!\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "# adam=Adam(learning_rate=0.001)\n",
    "# rmsprop=RMSprop(learning_rate=0.001)\n",
    "# adagrad=Adagrad(learning_rate=0.01)\n",
    "# nadam=Nadam(learning_rate=0.001,beta_1=-0.9,beta_2=0.999)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(128,input_shape=(len(train_x[0]),),activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(32,activation=\"relu\"))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(len(train_y[0]),activation='softmax'))\n",
    "\n",
    "\n",
    "sgd=SGD(learning_rate=0.01,decay=1e-6,momentum=0.5,nesterov=True)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=sgd,metrics=[\"accuracy\"])\n",
    "hist=model.fit(np.array(train_x),np.array(train_y),epochs=200,batch_size=2,verbose=1)\n",
    "model.save(\"./Model/Model_Chatbot_Personal.h5\",hist)\n",
    "\n",
    "print(\"Model Created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Initialize Random Forest classifier\n",
    "# model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# # Training the model\n",
    "# model.fit(train_x, train_y)\n",
    "\n",
    "# # Evaluating the model\n",
    "# accuracy = model.score(train_x, train_y)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- ----------\n",
      "anyio                     4.1.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     23.1.0\n",
      "Babel                     2.13.1\n",
      "beautifulsoup4            4.12.2\n",
      "bleach                    6.1.0\n",
      "blinker                   1.7.0\n",
      "certifi                   2021.5.30\n",
      "cffi                      1.16.0\n",
      "chardet                   4.0.0\n",
      "charset-normalizer        3.3.2\n",
      "click                     8.1.7\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.0\n",
      "contourpy                 1.2.0\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.0\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "distlib                   0.3.7\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.19.0\n",
      "filelock                  3.13.1\n",
      "Flask                     3.0.2\n",
      "flask-ngrok               0.0.25\n",
      "fonttools                 4.49.0\n",
      "fqdn                      1.5.1\n",
      "idna                      2.10\n",
      "ipykernel                 6.27.1\n",
      "ipython                   8.18.1\n",
      "isoduration               20.11.0\n",
      "itsdangerous              2.1.2\n",
      "jedi                      0.17.2\n",
      "Jinja2                    3.1.3\n",
      "joblib                    1.3.2\n",
      "json5                     0.9.14\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.20.0\n",
      "jsonschema-specifications 2023.11.1\n",
      "jupyter_client            8.6.0\n",
      "jupyter_core              5.5.0\n",
      "jupyter-events            0.9.0\n",
      "jupyter-lsp               2.2.1\n",
      "jupyter_server            2.11.1\n",
      "jupyter_server_terminals  0.4.4\n",
      "jupyterlab                4.0.9\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.25.2\n",
      "kiwisolver                1.4.5\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.8.3\n",
      "matplotlib-inline         0.1.6\n",
      "mistune                   3.0.2\n",
      "nbclient                  0.9.0\n",
      "nbconvert                 7.11.0\n",
      "nbformat                  5.9.2\n",
      "nest-asyncio              1.5.8\n",
      "nltk                      3.8.1\n",
      "notebook_shim             0.2.3\n",
      "numpy                     1.26.4\n",
      "opencv-python             4.9.0.80\n",
      "overrides                 7.4.0\n",
      "packaging                 23.2\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.7.1\n",
      "Pillow                    10.1.0\n",
      "pip                       23.3.1\n",
      "platformdirs              4.0.0\n",
      "pluggy                    1.4.0\n",
      "prometheus-client         0.19.0\n",
      "prompt-toolkit            3.0.41\n",
      "psutil                    5.9.6\n",
      "pure-eval                 0.2.2\n",
      "pycparser                 2.21\n",
      "Pygments                  2.17.2\n",
      "pyparsing                 3.1.2\n",
      "python-dateutil           2.8.2\n",
      "python-json-logger        2.0.7\n",
      "python-jsonrpc-server     0.4.0\n",
      "python-language-server    0.36.2\n",
      "PyWavelets                1.5.0\n",
      "pywin32                   306\n",
      "pywinpty                  2.0.12\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.1\n",
      "referencing               0.31.0\n",
      "regex                     2023.12.25\n",
      "requests                  2.25.1\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.13.1\n",
      "Send2Trash                1.8.2\n",
      "setuptools                69.0.2\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.0\n",
      "soupsieve                 2.5\n",
      "stack-data                0.6.3\n",
      "terminado                 0.18.0\n",
      "tinycss2                  1.2.1\n",
      "tkdesigner                1.0.3\n",
      "tornado                   6.3.3\n",
      "tqdm                      4.66.2\n",
      "traitlets                 5.14.0\n",
      "types-python-dateutil     2.8.19.14\n",
      "ujson                     5.9.0\n",
      "uri-template              1.3.0\n",
      "urllib3                   1.26.6\n",
      "virtualenv                20.24.7\n",
      "wcwidth                   0.2.12\n",
      "webcolors                 1.13\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.6.4\n",
      "Werkzeug                  3.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=[1,2,3,4,5,6,9]\n",
    "test2=[0]*len(test)\n",
    "test2[test.index(3)]=1\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"running\",pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
